{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from utils.csv_to_pd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:14:06.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.48</td>\n",
       "      <td>15.59</td>\n",
       "      <td>94.3</td>\n",
       "      <td>652.92</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationCode                 DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0            10  2024-03-01 17:14:06.000             0.0        1017.48   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0            15.59         94.3         652.92       0.12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dir_csv()\n",
    "\n",
    "location_ori = list(df[\"LocationCode\"]) \n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00          10.0        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  hour  \n",
       "0        15.712857    93.771429     652.797143   0.115714    17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mean_10min(df)\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>171.555961</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>2.273539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00    171.555961        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)      hour  \n",
       "0        15.712857    93.771429     652.797143   0.115714  2.273539  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=[\"LocationCode\", \"hour\"], sigma = 0.05)\n",
    "encoder.fit(df, df['Power(mW)'])\n",
    "df = encoder.transform(df)\n",
    "\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>-0.757742</td>\n",
       "      <td>-0.284717</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>-1.640724</td>\n",
       "      <td>0.974532</td>\n",
       "      <td>-0.721713</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>-1.015733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00     -0.757742       -0.284717       0.741951   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)      hour  \n",
       "0        -1.640724     0.974532      -0.721713   0.115714 -1.015733  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定要標準化的欄位\n",
    "columns_to_standardize = ['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)', \"LocationCode\", \"hour\"]\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 對指定欄位進行標準化\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_data_random(data_label_list, train_ratio=0.95):\n",
    "\n",
    "    # 創建索引列表並隨機打亂\n",
    "    indices = list(range(len(data_label_list)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # 計算分割點\n",
    "    train_size = int(len(data_label_list) * train_ratio)\n",
    "\n",
    "    # 分配數據\n",
    "    train_indices = indices[:train_size]\n",
    "    valid_indices = indices[train_size:]\n",
    "\n",
    "    # 根據索引分割數據\n",
    "    train_data_label_list = [data_label_list[i] for i in train_indices]\n",
    "    valid_data_label_list = [data_label_list[i] for i in valid_indices]\n",
    "\n",
    "\n",
    "    return train_data_label_list, valid_data_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_list, _ = spilt_data_with_datetime(df, location_ori)\n",
    "\n",
    "train_data_label_list, valid_data_label_list = split_data_random(data_label_list)\n",
    "\n",
    "train_data, train_label, train_length = sort_by_length(train_data_label_list)\n",
    "valid_data, valid_label, valid_length = sort_by_length(valid_data_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def padding(data_list, label_list, length, batch=64):\n",
    "\n",
    "    batch_data_list = []\n",
    "    batch_label_list = []\n",
    "    batch_length = []\n",
    "\n",
    "    for i in range(0, len(data_list), batch):\n",
    "        upper = min(len(data_list), i + batch)\n",
    "        data = pad_sequence(data_list[i:upper], batch_first=True, padding_value=0)\n",
    "        label = pad_sequence(label_list[i:upper], batch_first=True, padding_value=0)\n",
    "        batch_data_list.append(data)\n",
    "        batch_label_list.append(label)\n",
    "        batch_length.append(torch.tensor(length[i:upper]))\n",
    "    return batch_data_list, batch_label_list, batch_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_train_data, batch_train_label, batch_train_length = padding(train_data, train_label, train_length)\n",
    "batch_valid_data, batch_valid_label, batch_valid_length = padding(valid_data, valid_label, valid_length)\n",
    "\n",
    "batch_train_data[-1].shape\n",
    "\n",
    "train_loader = list(zip(batch_train_data, batch_train_label, batch_train_length))\n",
    "valid_loader = list(zip(batch_valid_data, batch_valid_label, batch_valid_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, tagset_size, input_dim=6):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM層\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # 線性層\n",
    "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence, hidden, lengths):\n",
    "        \"\"\"\n",
    "        sentence: Tensor, shape (batch_size, seq_len, input_dim)\n",
    "        lengths: List of sequence lengths (before padding)\n",
    "        hidden: Initial hidden state\n",
    "\n",
    "        Returns:\n",
    "            tag_space: Tensor, shape (batch_size, seq_len, tagset_size)\n",
    "            hidden: Final hidden state\n",
    "        \"\"\"\n",
    "        # 動態打包序列\n",
    "        packed_input = pack_padded_sequence(sentence, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # LSTM層\n",
    "        packed_output, hidden = self.lstm(packed_input, hidden)\n",
    "\n",
    "        # 解包序列\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # lstm_out, hidden = self.lstm(sentence, hidden)\n",
    "        # 線性層和激活函數\n",
    "        tag_space = self.relu(self.linear(self.relu(lstm_out)))\n",
    "\n",
    "        return tag_space, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# 設置 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定義訓練函數\n",
    "def train_model(model, train_loader, valid_loader, train_length, valid_length, num_epochs=10, learning_rate=0.001):\n",
    "    # 將模型移到 GPU\n",
    "    model = model.to(device, dtype=torch.float32)\n",
    "    # 使用 Adam 優化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # 定義損失函數\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for inputs, labels, length in train_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels, length = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32), length.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            \n",
    "\n",
    "            # 清零梯度\n",
    "            optimizer.zero_grad()\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden, length)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            # 更新參數\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss / train_length:.4f}\")\n",
    "\n",
    "        # 驗證模型\n",
    "        validate_model(model, valid_loader, criterion, valid_length)\n",
    "\n",
    "# 定義驗證函數\n",
    "def validate_model(model, valid_loader, criterion, valid_length):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    error = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, length in valid_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels, length = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32), length.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden, length)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            error += abs(outputs.view(-1) - labels.view(-1)).sum() / inputs.shape[0] / inputs.shape[1]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {total_loss / valid_length:.4f}, valid error: {error / valid_length}\")\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 209.0888\n",
      "Validation Loss: 151.0277, valid error: 151.3748016357422\n",
      "Epoch [2/500], Training Loss: 207.4958\n",
      "Validation Loss: 150.4292, valid error: 150.77407836914062\n",
      "Epoch [3/500], Training Loss: 206.8555\n",
      "Validation Loss: 150.1667, valid error: 150.52328491210938\n",
      "Epoch [4/500], Training Loss: 206.3188\n",
      "Validation Loss: 150.0091, valid error: 150.36508178710938\n",
      "Epoch [5/500], Training Loss: 205.9515\n",
      "Validation Loss: 149.9818, valid error: 150.34471130371094\n",
      "Epoch [6/500], Training Loss: 205.4910\n",
      "Validation Loss: 149.7435, valid error: 150.1033477783203\n",
      "Epoch [7/500], Training Loss: 205.2710\n",
      "Validation Loss: 148.7288, valid error: 149.09402465820312\n",
      "Epoch [8/500], Training Loss: 204.6983\n",
      "Validation Loss: 148.6452, valid error: 149.0135040283203\n",
      "Epoch [9/500], Training Loss: 202.4234\n",
      "Validation Loss: 145.9071, valid error: 146.27822875976562\n",
      "Epoch [10/500], Training Loss: 199.7456\n",
      "Validation Loss: 144.6718, valid error: 145.03475952148438\n",
      "Epoch [11/500], Training Loss: 197.9543\n",
      "Validation Loss: 143.4306, valid error: 143.8037567138672\n",
      "Epoch [12/500], Training Loss: 196.3571\n",
      "Validation Loss: 142.4122, valid error: 142.79217529296875\n",
      "Epoch [13/500], Training Loss: 194.7384\n",
      "Validation Loss: 141.3633, valid error: 141.74411010742188\n",
      "Epoch [14/500], Training Loss: 193.3738\n",
      "Validation Loss: 140.8377, valid error: 141.22520446777344\n",
      "Epoch [15/500], Training Loss: 191.8889\n",
      "Validation Loss: 139.7068, valid error: 140.0909423828125\n",
      "Epoch [16/500], Training Loss: 190.5102\n",
      "Validation Loss: 138.7416, valid error: 139.13478088378906\n",
      "Epoch [17/500], Training Loss: 189.1975\n",
      "Validation Loss: 137.9770, valid error: 138.37451171875\n",
      "Epoch [18/500], Training Loss: 187.7591\n",
      "Validation Loss: 136.8711, valid error: 137.2669219970703\n",
      "Epoch [19/500], Training Loss: 186.3831\n",
      "Validation Loss: 135.5836, valid error: 135.98458862304688\n",
      "Epoch [20/500], Training Loss: 185.4387\n",
      "Validation Loss: 135.6380, valid error: 136.04513549804688\n",
      "Epoch [21/500], Training Loss: 184.0323\n",
      "Validation Loss: 134.5729, valid error: 134.98162841796875\n",
      "Epoch [22/500], Training Loss: 182.6545\n",
      "Validation Loss: 132.9679, valid error: 133.3977508544922\n",
      "Epoch [23/500], Training Loss: 182.4702\n",
      "Validation Loss: 133.4657, valid error: 133.8756866455078\n",
      "Epoch [24/500], Training Loss: 181.2485\n",
      "Validation Loss: 132.2561, valid error: 132.6825408935547\n",
      "Epoch [25/500], Training Loss: 179.5791\n",
      "Validation Loss: 131.2200, valid error: 131.65322875976562\n",
      "Epoch [26/500], Training Loss: 178.2905\n",
      "Validation Loss: 130.1647, valid error: 130.57894897460938\n",
      "Epoch [27/500], Training Loss: 177.0956\n",
      "Validation Loss: 129.2975, valid error: 129.72454833984375\n",
      "Epoch [28/500], Training Loss: 176.0629\n",
      "Validation Loss: 128.6647, valid error: 129.09884643554688\n",
      "Epoch [29/500], Training Loss: 174.9178\n",
      "Validation Loss: 127.6741, valid error: 128.12167358398438\n",
      "Epoch [30/500], Training Loss: 174.0855\n",
      "Validation Loss: 127.1402, valid error: 127.56217956542969\n",
      "Epoch [31/500], Training Loss: 172.8547\n",
      "Validation Loss: 126.3551, valid error: 126.77421569824219\n",
      "Epoch [32/500], Training Loss: 171.7851\n",
      "Validation Loss: 125.5382, valid error: 125.96115112304688\n",
      "Epoch [33/500], Training Loss: 170.7841\n",
      "Validation Loss: 124.7465, valid error: 125.18098449707031\n",
      "Epoch [34/500], Training Loss: 169.7925\n",
      "Validation Loss: 123.9622, valid error: 124.38536071777344\n",
      "Epoch [35/500], Training Loss: 168.7754\n",
      "Validation Loss: 123.3050, valid error: 123.72300720214844\n",
      "Epoch [36/500], Training Loss: 167.8344\n",
      "Validation Loss: 122.6181, valid error: 123.0423583984375\n",
      "Epoch [37/500], Training Loss: 166.8620\n",
      "Validation Loss: 121.9415, valid error: 122.35835266113281\n",
      "Epoch [38/500], Training Loss: 165.8802\n",
      "Validation Loss: 121.2733, valid error: 121.69013977050781\n",
      "Epoch [39/500], Training Loss: 164.9278\n",
      "Validation Loss: 120.7349, valid error: 121.15316772460938\n",
      "Epoch [40/500], Training Loss: 164.0447\n",
      "Validation Loss: 120.0606, valid error: 120.47904968261719\n",
      "Epoch [41/500], Training Loss: 163.1251\n",
      "Validation Loss: 119.4127, valid error: 119.83253479003906\n",
      "Epoch [42/500], Training Loss: 162.2405\n",
      "Validation Loss: 118.7340, valid error: 119.15287780761719\n",
      "Epoch [43/500], Training Loss: 161.3171\n",
      "Validation Loss: 118.1183, valid error: 118.53759765625\n",
      "Epoch [44/500], Training Loss: 160.3092\n",
      "Validation Loss: 117.4731, valid error: 117.89453125\n",
      "Epoch [45/500], Training Loss: 159.2832\n",
      "Validation Loss: 116.7771, valid error: 117.19964599609375\n",
      "Epoch [46/500], Training Loss: 158.2937\n",
      "Validation Loss: 116.1793, valid error: 116.60414123535156\n",
      "Epoch [47/500], Training Loss: 157.3696\n",
      "Validation Loss: 115.4773, valid error: 115.90336608886719\n",
      "Epoch [48/500], Training Loss: 156.3666\n",
      "Validation Loss: 114.6870, valid error: 115.10978698730469\n",
      "Epoch [49/500], Training Loss: 155.3934\n",
      "Validation Loss: 114.0798, valid error: 114.50218200683594\n",
      "Epoch [50/500], Training Loss: 154.4798\n",
      "Validation Loss: 113.6174, valid error: 114.04449462890625\n",
      "Epoch [51/500], Training Loss: 153.6220\n",
      "Validation Loss: 112.9059, valid error: 113.32752990722656\n",
      "Epoch [52/500], Training Loss: 152.7814\n",
      "Validation Loss: 112.3071, valid error: 112.73446655273438\n",
      "Epoch [53/500], Training Loss: 151.9646\n",
      "Validation Loss: 111.6999, valid error: 112.12606811523438\n",
      "Epoch [54/500], Training Loss: 150.9884\n",
      "Validation Loss: 111.0010, valid error: 111.42262268066406\n",
      "Epoch [55/500], Training Loss: 150.2509\n",
      "Validation Loss: 110.1521, valid error: 110.56903076171875\n",
      "Epoch [56/500], Training Loss: 149.2943\n",
      "Validation Loss: 109.5009, valid error: 109.9173812866211\n",
      "Epoch [57/500], Training Loss: 148.3037\n",
      "Validation Loss: 108.9683, valid error: 109.38473510742188\n",
      "Epoch [58/500], Training Loss: 147.3172\n",
      "Validation Loss: 108.3702, valid error: 108.78775024414062\n",
      "Epoch [59/500], Training Loss: 146.5605\n",
      "Validation Loss: 107.5985, valid error: 108.01378631591797\n",
      "Epoch [60/500], Training Loss: 145.5426\n",
      "Validation Loss: 107.1751, valid error: 107.59197235107422\n",
      "Epoch [61/500], Training Loss: 144.7260\n",
      "Validation Loss: 106.7553, valid error: 107.1724853515625\n",
      "Epoch [62/500], Training Loss: 143.8018\n",
      "Validation Loss: 106.1336, valid error: 106.55096435546875\n",
      "Epoch [63/500], Training Loss: 142.9570\n",
      "Validation Loss: 105.6331, valid error: 106.05242919921875\n",
      "Epoch [64/500], Training Loss: 142.1311\n",
      "Validation Loss: 104.8328, valid error: 105.25360870361328\n",
      "Epoch [65/500], Training Loss: 141.2035\n",
      "Validation Loss: 104.4191, valid error: 104.84791564941406\n",
      "Epoch [66/500], Training Loss: 140.3184\n",
      "Validation Loss: 103.6193, valid error: 104.04605865478516\n",
      "Epoch [67/500], Training Loss: 139.3703\n",
      "Validation Loss: 102.9859, valid error: 103.41751098632812\n",
      "Epoch [68/500], Training Loss: 138.4225\n",
      "Validation Loss: 102.3783, valid error: 102.8042984008789\n",
      "Epoch [69/500], Training Loss: 137.5602\n",
      "Validation Loss: 101.6895, valid error: 102.11213684082031\n",
      "Epoch [70/500], Training Loss: 136.6511\n",
      "Validation Loss: 100.9941, valid error: 101.41593170166016\n",
      "Epoch [71/500], Training Loss: 135.8229\n",
      "Validation Loss: 100.3689, valid error: 100.79314422607422\n",
      "Epoch [72/500], Training Loss: 135.0334\n",
      "Validation Loss: 99.5646, valid error: 99.97572326660156\n",
      "Epoch [73/500], Training Loss: 134.0368\n",
      "Validation Loss: 99.2050, valid error: 99.62223052978516\n",
      "Epoch [74/500], Training Loss: 133.2436\n",
      "Validation Loss: 98.3846, valid error: 98.80194854736328\n",
      "Epoch [75/500], Training Loss: 132.4179\n",
      "Validation Loss: 97.9929, valid error: 98.40805053710938\n",
      "Epoch [76/500], Training Loss: 131.6014\n",
      "Validation Loss: 97.5053, valid error: 97.923583984375\n",
      "Epoch [77/500], Training Loss: 130.7864\n",
      "Validation Loss: 96.8559, valid error: 97.2718276977539\n",
      "Epoch [78/500], Training Loss: 129.9630\n",
      "Validation Loss: 96.2761, valid error: 96.69155883789062\n",
      "Epoch [79/500], Training Loss: 129.3123\n",
      "Validation Loss: 96.1220, valid error: 96.54924011230469\n",
      "Epoch [80/500], Training Loss: 128.5560\n",
      "Validation Loss: 95.3669, valid error: 95.79004669189453\n",
      "Epoch [81/500], Training Loss: 127.6698\n",
      "Validation Loss: 94.8738, valid error: 95.30291748046875\n",
      "Epoch [82/500], Training Loss: 126.8188\n",
      "Validation Loss: 94.1787, valid error: 94.60690307617188\n",
      "Epoch [83/500], Training Loss: 126.0920\n",
      "Validation Loss: 93.6763, valid error: 94.1124267578125\n",
      "Epoch [84/500], Training Loss: 125.2133\n",
      "Validation Loss: 93.2494, valid error: 93.68323516845703\n",
      "Epoch [85/500], Training Loss: 124.7038\n",
      "Validation Loss: 92.9230, valid error: 93.35317993164062\n",
      "Epoch [86/500], Training Loss: 123.8732\n",
      "Validation Loss: 91.8092, valid error: 92.23599243164062\n",
      "Epoch [87/500], Training Loss: 122.7729\n",
      "Validation Loss: 91.5512, valid error: 91.97232055664062\n",
      "Epoch [88/500], Training Loss: 122.0284\n",
      "Validation Loss: 90.9289, valid error: 91.36444091796875\n",
      "Epoch [89/500], Training Loss: 121.1282\n",
      "Validation Loss: 90.1977, valid error: 90.61978912353516\n",
      "Epoch [90/500], Training Loss: 120.2763\n",
      "Validation Loss: 89.9015, valid error: 90.31846618652344\n",
      "Epoch [91/500], Training Loss: 119.4888\n",
      "Validation Loss: 89.2793, valid error: 89.70401000976562\n",
      "Epoch [92/500], Training Loss: 118.6829\n",
      "Validation Loss: 88.7192, valid error: 89.14482879638672\n",
      "Epoch [93/500], Training Loss: 117.8487\n",
      "Validation Loss: 88.0979, valid error: 88.51942443847656\n",
      "Epoch [94/500], Training Loss: 117.0662\n",
      "Validation Loss: 87.7409, valid error: 88.16706085205078\n",
      "Epoch [95/500], Training Loss: 116.2992\n",
      "Validation Loss: 87.0736, valid error: 87.49420166015625\n",
      "Epoch [96/500], Training Loss: 115.4431\n",
      "Validation Loss: 86.5443, valid error: 86.96509552001953\n",
      "Epoch [97/500], Training Loss: 114.7320\n",
      "Validation Loss: 86.2588, valid error: 86.6795425415039\n",
      "Epoch [98/500], Training Loss: 113.9468\n",
      "Validation Loss: 85.6231, valid error: 86.04058837890625\n",
      "Epoch [99/500], Training Loss: 113.0809\n",
      "Validation Loss: 85.1426, valid error: 85.56239318847656\n",
      "Epoch [100/500], Training Loss: 112.3870\n",
      "Validation Loss: 84.6899, valid error: 85.10865783691406\n",
      "Epoch [101/500], Training Loss: 111.8368\n",
      "Validation Loss: 84.2249, valid error: 84.64738464355469\n",
      "Epoch [102/500], Training Loss: 110.9968\n",
      "Validation Loss: 83.8124, valid error: 84.23255920410156\n",
      "Epoch [103/500], Training Loss: 110.4861\n",
      "Validation Loss: 83.4713, valid error: 83.89825439453125\n",
      "Epoch [104/500], Training Loss: 110.0174\n",
      "Validation Loss: 82.8034, valid error: 83.22315979003906\n",
      "Epoch [105/500], Training Loss: 108.9982\n",
      "Validation Loss: 82.5055, valid error: 82.92096710205078\n",
      "Epoch [106/500], Training Loss: 108.3752\n",
      "Validation Loss: 82.0602, valid error: 82.47516632080078\n",
      "Epoch [107/500], Training Loss: 107.5961\n",
      "Validation Loss: 81.3221, valid error: 81.74158477783203\n",
      "Epoch [108/500], Training Loss: 106.8412\n",
      "Validation Loss: 80.9292, valid error: 81.34722900390625\n",
      "Epoch [109/500], Training Loss: 106.2079\n",
      "Validation Loss: 80.3169, valid error: 80.7341537475586\n",
      "Epoch [110/500], Training Loss: 105.9172\n",
      "Validation Loss: 79.5983, valid error: 80.01319122314453\n",
      "Epoch [111/500], Training Loss: 105.2115\n",
      "Validation Loss: 79.6704, valid error: 80.09112548828125\n",
      "Epoch [112/500], Training Loss: 104.1691\n",
      "Validation Loss: 79.2832, valid error: 79.7044677734375\n",
      "Epoch [113/500], Training Loss: 103.3295\n",
      "Validation Loss: 78.8908, valid error: 79.30705261230469\n",
      "Epoch [114/500], Training Loss: 102.8421\n",
      "Validation Loss: 78.4010, valid error: 78.8155288696289\n",
      "Epoch [115/500], Training Loss: 102.2404\n",
      "Validation Loss: 78.0473, valid error: 78.46365356445312\n",
      "Epoch [116/500], Training Loss: 101.3345\n",
      "Validation Loss: 76.9561, valid error: 77.36845397949219\n",
      "Epoch [117/500], Training Loss: 100.5369\n",
      "Validation Loss: 76.8554, valid error: 77.26557922363281\n",
      "Epoch [118/500], Training Loss: 100.0286\n",
      "Validation Loss: 76.4242, valid error: 76.8382339477539\n",
      "Epoch [119/500], Training Loss: 99.1801\n",
      "Validation Loss: 75.4008, valid error: 75.81185150146484\n",
      "Epoch [120/500], Training Loss: 98.4683\n",
      "Validation Loss: 75.5039, valid error: 75.9100570678711\n",
      "Epoch [121/500], Training Loss: 97.6875\n",
      "Validation Loss: 74.5531, valid error: 74.96055603027344\n",
      "Epoch [122/500], Training Loss: 96.9319\n",
      "Validation Loss: 74.4493, valid error: 74.85908508300781\n",
      "Epoch [123/500], Training Loss: 96.5853\n",
      "Validation Loss: 74.5131, valid error: 74.9277114868164\n",
      "Epoch [124/500], Training Loss: 96.4531\n",
      "Validation Loss: 73.9721, valid error: 74.39277648925781\n",
      "Epoch [125/500], Training Loss: 95.3344\n",
      "Validation Loss: 73.0955, valid error: 73.51068115234375\n",
      "Epoch [126/500], Training Loss: 94.2953\n",
      "Validation Loss: 72.5153, valid error: 72.92843627929688\n",
      "Epoch [127/500], Training Loss: 93.5517\n",
      "Validation Loss: 72.2903, valid error: 72.70177459716797\n",
      "Epoch [128/500], Training Loss: 92.9476\n",
      "Validation Loss: 71.7428, valid error: 72.14840698242188\n",
      "Epoch [129/500], Training Loss: 92.4162\n",
      "Validation Loss: 71.6283, valid error: 72.03829193115234\n",
      "Epoch [130/500], Training Loss: 91.7486\n",
      "Validation Loss: 70.9542, valid error: 71.36907958984375\n",
      "Epoch [131/500], Training Loss: 91.0902\n",
      "Validation Loss: 70.8195, valid error: 71.24063873291016\n",
      "Epoch [132/500], Training Loss: 90.5029\n",
      "Validation Loss: 70.5347, valid error: 70.95927429199219\n",
      "Epoch [133/500], Training Loss: 90.0905\n",
      "Validation Loss: 69.2890, valid error: 69.70867919921875\n",
      "Epoch [134/500], Training Loss: 89.0265\n",
      "Validation Loss: 68.8789, valid error: 69.2987060546875\n",
      "Epoch [135/500], Training Loss: 88.4336\n",
      "Validation Loss: 69.3284, valid error: 69.74658203125\n",
      "Epoch [136/500], Training Loss: 88.1658\n",
      "Validation Loss: 69.1229, valid error: 69.54487609863281\n",
      "Epoch [137/500], Training Loss: 88.0035\n",
      "Validation Loss: 68.0925, valid error: 68.5164794921875\n",
      "Epoch [138/500], Training Loss: 86.7203\n",
      "Validation Loss: 67.8888, valid error: 68.31117248535156\n",
      "Epoch [139/500], Training Loss: 85.8738\n",
      "Validation Loss: 67.3018, valid error: 67.71768951416016\n",
      "Epoch [140/500], Training Loss: 85.0756\n",
      "Validation Loss: 67.0117, valid error: 67.42655944824219\n",
      "Epoch [141/500], Training Loss: 84.6386\n",
      "Validation Loss: 66.7414, valid error: 67.15609741210938\n",
      "Epoch [142/500], Training Loss: 84.6613\n",
      "Validation Loss: 66.2791, valid error: 66.7037353515625\n",
      "Epoch [143/500], Training Loss: 83.8446\n",
      "Validation Loss: 66.2272, valid error: 66.64761352539062\n",
      "Epoch [144/500], Training Loss: 82.9746\n",
      "Validation Loss: 65.3697, valid error: 65.79052734375\n",
      "Epoch [145/500], Training Loss: 82.3262\n",
      "Validation Loss: 65.0669, valid error: 65.48274230957031\n",
      "Epoch [146/500], Training Loss: 81.7081\n",
      "Validation Loss: 64.8242, valid error: 65.24153900146484\n",
      "Epoch [147/500], Training Loss: 80.9311\n",
      "Validation Loss: 64.3876, valid error: 64.80245208740234\n",
      "Epoch [148/500], Training Loss: 80.4493\n",
      "Validation Loss: 63.9654, valid error: 64.3827896118164\n",
      "Epoch [149/500], Training Loss: 80.0267\n",
      "Validation Loss: 63.4685, valid error: 63.89216995239258\n",
      "Epoch [150/500], Training Loss: 79.4520\n",
      "Validation Loss: 63.1026, valid error: 63.519012451171875\n",
      "Epoch [151/500], Training Loss: 78.7013\n",
      "Validation Loss: 63.0275, valid error: 63.443389892578125\n",
      "Epoch [152/500], Training Loss: 78.1445\n",
      "Validation Loss: 62.6680, valid error: 63.084503173828125\n",
      "Epoch [153/500], Training Loss: 77.6061\n",
      "Validation Loss: 62.2813, valid error: 62.700950622558594\n",
      "Epoch [154/500], Training Loss: 77.0747\n",
      "Validation Loss: 61.8808, valid error: 62.304107666015625\n",
      "Epoch [155/500], Training Loss: 76.7025\n",
      "Validation Loss: 61.6872, valid error: 62.12534713745117\n",
      "Epoch [156/500], Training Loss: 76.9352\n",
      "Validation Loss: 61.2249, valid error: 61.650428771972656\n",
      "Epoch [157/500], Training Loss: 76.3696\n",
      "Validation Loss: 61.0662, valid error: 61.49571990966797\n",
      "Epoch [158/500], Training Loss: 75.5907\n",
      "Validation Loss: 60.5484, valid error: 60.97557067871094\n",
      "Epoch [159/500], Training Loss: 74.8974\n",
      "Validation Loss: 60.4110, valid error: 60.83830261230469\n",
      "Epoch [160/500], Training Loss: 74.4679\n",
      "Validation Loss: 59.9657, valid error: 60.38370132446289\n",
      "Epoch [161/500], Training Loss: 74.7373\n",
      "Validation Loss: 59.6370, valid error: 60.0541877746582\n",
      "Epoch [162/500], Training Loss: 73.7532\n",
      "Validation Loss: 59.5794, valid error: 59.997371673583984\n",
      "Epoch [163/500], Training Loss: 73.4253\n",
      "Validation Loss: 59.0475, valid error: 59.46938705444336\n",
      "Epoch [164/500], Training Loss: 72.3910\n",
      "Validation Loss: 58.3612, valid error: 58.77361297607422\n",
      "Epoch [165/500], Training Loss: 71.5700\n",
      "Validation Loss: 57.8227, valid error: 58.242103576660156\n",
      "Epoch [166/500], Training Loss: 71.0585\n",
      "Validation Loss: 57.4082, valid error: 57.83154296875\n",
      "Epoch [167/500], Training Loss: 70.7279\n",
      "Validation Loss: 57.1953, valid error: 57.615760803222656\n",
      "Epoch [168/500], Training Loss: 70.0179\n",
      "Validation Loss: 56.9657, valid error: 57.388641357421875\n",
      "Epoch [169/500], Training Loss: 69.7411\n",
      "Validation Loss: 56.3911, valid error: 56.81214141845703\n",
      "Epoch [170/500], Training Loss: 69.0622\n",
      "Validation Loss: 56.5991, valid error: 57.01384735107422\n",
      "Epoch [171/500], Training Loss: 68.9583\n",
      "Validation Loss: 55.7175, valid error: 56.13604736328125\n",
      "Epoch [172/500], Training Loss: 68.0990\n",
      "Validation Loss: 55.8586, valid error: 56.280372619628906\n",
      "Epoch [173/500], Training Loss: 67.3172\n",
      "Validation Loss: 55.0922, valid error: 55.51097869873047\n",
      "Epoch [174/500], Training Loss: 66.6413\n",
      "Validation Loss: 54.8655, valid error: 55.27754211425781\n",
      "Epoch [175/500], Training Loss: 66.2954\n",
      "Validation Loss: 55.1025, valid error: 55.519805908203125\n",
      "Epoch [176/500], Training Loss: 66.1194\n",
      "Validation Loss: 54.7332, valid error: 55.146217346191406\n",
      "Epoch [177/500], Training Loss: 65.4194\n",
      "Validation Loss: 54.6227, valid error: 55.037471771240234\n",
      "Epoch [178/500], Training Loss: 64.7460\n",
      "Validation Loss: 54.6711, valid error: 55.08172607421875\n",
      "Epoch [179/500], Training Loss: 64.4967\n",
      "Validation Loss: 54.0019, valid error: 54.41370391845703\n",
      "Epoch [180/500], Training Loss: 63.8459\n",
      "Validation Loss: 54.1734, valid error: 54.585792541503906\n",
      "Epoch [181/500], Training Loss: 64.2003\n",
      "Validation Loss: 53.4837, valid error: 53.895748138427734\n",
      "Epoch [182/500], Training Loss: 64.0122\n",
      "Validation Loss: 53.6240, valid error: 54.04257583618164\n",
      "Epoch [183/500], Training Loss: 63.5798\n",
      "Validation Loss: 52.2702, valid error: 52.68459701538086\n",
      "Epoch [184/500], Training Loss: 62.3870\n",
      "Validation Loss: 51.9400, valid error: 52.35200881958008\n",
      "Epoch [185/500], Training Loss: 61.8081\n",
      "Validation Loss: 51.7854, valid error: 52.19483947753906\n",
      "Epoch [186/500], Training Loss: 61.3340\n",
      "Validation Loss: 51.8526, valid error: 52.26421356201172\n",
      "Epoch [187/500], Training Loss: 60.6695\n",
      "Validation Loss: 51.9594, valid error: 52.37036895751953\n",
      "Epoch [188/500], Training Loss: 60.1812\n",
      "Validation Loss: 51.3408, valid error: 51.75567626953125\n",
      "Epoch [189/500], Training Loss: 60.1070\n",
      "Validation Loss: 50.8373, valid error: 51.25646209716797\n",
      "Epoch [190/500], Training Loss: 59.7588\n",
      "Validation Loss: 51.3602, valid error: 51.781375885009766\n",
      "Epoch [191/500], Training Loss: 59.4236\n",
      "Validation Loss: 50.1191, valid error: 50.53608703613281\n",
      "Epoch [192/500], Training Loss: 59.0476\n",
      "Validation Loss: 50.5301, valid error: 50.943214416503906\n",
      "Epoch [193/500], Training Loss: 58.3490\n",
      "Validation Loss: 49.4925, valid error: 49.90563201904297\n",
      "Epoch [194/500], Training Loss: 57.7766\n",
      "Validation Loss: 49.4051, valid error: 49.819679260253906\n",
      "Epoch [195/500], Training Loss: 57.3160\n",
      "Validation Loss: 48.8798, valid error: 49.288169860839844\n",
      "Epoch [196/500], Training Loss: 56.6335\n",
      "Validation Loss: 48.8591, valid error: 49.27278518676758\n",
      "Epoch [197/500], Training Loss: 56.0264\n",
      "Validation Loss: 48.3549, valid error: 48.765586853027344\n",
      "Epoch [198/500], Training Loss: 55.6083\n",
      "Validation Loss: 48.3156, valid error: 48.726341247558594\n",
      "Epoch [199/500], Training Loss: 55.3000\n",
      "Validation Loss: 48.1462, valid error: 48.56241226196289\n",
      "Epoch [200/500], Training Loss: 54.8186\n",
      "Validation Loss: 48.0291, valid error: 48.45090103149414\n",
      "Epoch [201/500], Training Loss: 55.2187\n",
      "Validation Loss: 47.8780, valid error: 48.29435729980469\n",
      "Epoch [202/500], Training Loss: 54.9740\n",
      "Validation Loss: 47.2624, valid error: 47.67327117919922\n",
      "Epoch [203/500], Training Loss: 54.6457\n",
      "Validation Loss: 47.4144, valid error: 47.828617095947266\n",
      "Epoch [204/500], Training Loss: 54.7432\n",
      "Validation Loss: 48.0892, valid error: 48.50163269042969\n",
      "Epoch [205/500], Training Loss: 53.6987\n",
      "Validation Loss: 47.9447, valid error: 48.35697555541992\n",
      "Epoch [206/500], Training Loss: 53.3348\n",
      "Validation Loss: 46.8619, valid error: 47.27975845336914\n",
      "Epoch [207/500], Training Loss: 52.5156\n",
      "Validation Loss: 46.5277, valid error: 46.94114685058594\n",
      "Epoch [208/500], Training Loss: 52.3810\n",
      "Validation Loss: 46.3194, valid error: 46.73403549194336\n",
      "Epoch [209/500], Training Loss: 51.8261\n",
      "Validation Loss: 46.0771, valid error: 46.491600036621094\n",
      "Epoch [210/500], Training Loss: 51.6245\n",
      "Validation Loss: 45.8490, valid error: 46.26609802246094\n",
      "Epoch [211/500], Training Loss: 51.0808\n",
      "Validation Loss: 46.0814, valid error: 46.50660705566406\n",
      "Epoch [212/500], Training Loss: 50.8874\n",
      "Validation Loss: 46.1765, valid error: 46.6121940612793\n",
      "Epoch [213/500], Training Loss: 51.8487\n",
      "Validation Loss: 45.1349, valid error: 45.56578826904297\n",
      "Epoch [214/500], Training Loss: 54.7238\n",
      "Validation Loss: 44.4945, valid error: 44.92972946166992\n",
      "Epoch [215/500], Training Loss: 52.0739\n",
      "Validation Loss: 43.9131, valid error: 44.341182708740234\n",
      "Epoch [216/500], Training Loss: 50.5376\n",
      "Validation Loss: 43.7629, valid error: 44.180450439453125\n",
      "Epoch [217/500], Training Loss: 49.8067\n",
      "Validation Loss: 43.1197, valid error: 43.545509338378906\n",
      "Epoch [218/500], Training Loss: 48.8572\n",
      "Validation Loss: 42.7649, valid error: 43.18425369262695\n",
      "Epoch [219/500], Training Loss: 47.9752\n",
      "Validation Loss: 42.3881, valid error: 42.806297302246094\n",
      "Epoch [220/500], Training Loss: 47.3221\n",
      "Validation Loss: 42.4955, valid error: 42.91507339477539\n",
      "Epoch [221/500], Training Loss: 46.9083\n",
      "Validation Loss: 42.2138, valid error: 42.63984680175781\n",
      "Epoch [222/500], Training Loss: 46.7203\n",
      "Validation Loss: 42.3208, valid error: 42.748207092285156\n",
      "Epoch [223/500], Training Loss: 46.3001\n",
      "Validation Loss: 41.8185, valid error: 42.24943923950195\n",
      "Epoch [224/500], Training Loss: 46.1480\n",
      "Validation Loss: 41.2984, valid error: 41.71799087524414\n",
      "Epoch [225/500], Training Loss: 45.5619\n",
      "Validation Loss: 41.3649, valid error: 41.784271240234375\n",
      "Epoch [226/500], Training Loss: 45.5687\n",
      "Validation Loss: 40.5494, valid error: 40.986228942871094\n",
      "Epoch [227/500], Training Loss: 45.1284\n",
      "Validation Loss: 40.5596, valid error: 40.98058319091797\n",
      "Epoch [228/500], Training Loss: 44.6416\n",
      "Validation Loss: 40.1784, valid error: 40.60875701904297\n",
      "Epoch [229/500], Training Loss: 44.2316\n",
      "Validation Loss: 39.7708, valid error: 40.19202423095703\n",
      "Epoch [230/500], Training Loss: 43.9049\n",
      "Validation Loss: 40.3083, valid error: 40.730804443359375\n",
      "Epoch [231/500], Training Loss: 43.7199\n",
      "Validation Loss: 39.8332, valid error: 40.26255416870117\n",
      "Epoch [232/500], Training Loss: 43.5453\n",
      "Validation Loss: 39.7807, valid error: 40.20218276977539\n",
      "Epoch [233/500], Training Loss: 43.2323\n",
      "Validation Loss: 39.6029, valid error: 40.02604293823242\n",
      "Epoch [234/500], Training Loss: 43.2258\n",
      "Validation Loss: 39.2840, valid error: 39.7079963684082\n",
      "Epoch [235/500], Training Loss: 42.7795\n",
      "Validation Loss: 39.1003, valid error: 39.52987289428711\n",
      "Epoch [236/500], Training Loss: 42.7815\n",
      "Validation Loss: 39.1623, valid error: 39.58799362182617\n",
      "Epoch [237/500], Training Loss: 42.6059\n",
      "Validation Loss: 39.4442, valid error: 39.85935974121094\n",
      "Epoch [238/500], Training Loss: 42.9144\n",
      "Validation Loss: 39.3873, valid error: 39.81486511230469\n",
      "Epoch [239/500], Training Loss: 43.0283\n",
      "Validation Loss: 38.4934, valid error: 38.91678237915039\n",
      "Epoch [240/500], Training Loss: 41.6802\n",
      "Validation Loss: 38.9303, valid error: 39.36148452758789\n",
      "Epoch [241/500], Training Loss: 40.3290\n",
      "Validation Loss: 37.7703, valid error: 38.197750091552734\n",
      "Epoch [242/500], Training Loss: 39.5219\n",
      "Validation Loss: 37.1868, valid error: 37.61772537231445\n",
      "Epoch [243/500], Training Loss: 39.0342\n",
      "Validation Loss: 36.9613, valid error: 37.38372802734375\n",
      "Epoch [244/500], Training Loss: 38.8188\n",
      "Validation Loss: 37.3352, valid error: 37.76344299316406\n",
      "Epoch [245/500], Training Loss: 39.3595\n",
      "Validation Loss: 37.5765, valid error: 38.01072692871094\n",
      "Epoch [246/500], Training Loss: 39.7348\n",
      "Validation Loss: 37.1683, valid error: 37.59418487548828\n",
      "Epoch [247/500], Training Loss: 39.1506\n",
      "Validation Loss: 36.7326, valid error: 37.15608215332031\n",
      "Epoch [248/500], Training Loss: 39.2636\n",
      "Validation Loss: 36.6787, valid error: 37.097503662109375\n",
      "Epoch [249/500], Training Loss: 38.7547\n",
      "Validation Loss: 36.7462, valid error: 37.15932083129883\n",
      "Epoch [250/500], Training Loss: 38.0344\n",
      "Validation Loss: 35.9971, valid error: 36.419517517089844\n",
      "Epoch [251/500], Training Loss: 37.7073\n",
      "Validation Loss: 35.3385, valid error: 35.75059509277344\n",
      "Epoch [252/500], Training Loss: 36.8747\n",
      "Validation Loss: 35.3802, valid error: 35.79871368408203\n",
      "Epoch [253/500], Training Loss: 36.3348\n",
      "Validation Loss: 34.7813, valid error: 35.195926666259766\n",
      "Epoch [254/500], Training Loss: 36.1538\n",
      "Validation Loss: 34.9046, valid error: 35.31791687011719\n",
      "Epoch [255/500], Training Loss: 36.2113\n",
      "Validation Loss: 35.4939, valid error: 35.91853332519531\n",
      "Epoch [256/500], Training Loss: 35.9826\n",
      "Validation Loss: 36.0094, valid error: 36.433143615722656\n",
      "Epoch [257/500], Training Loss: 35.4645\n",
      "Validation Loss: 35.4549, valid error: 35.87944412231445\n",
      "Epoch [258/500], Training Loss: 35.4457\n",
      "Validation Loss: 34.4772, valid error: 34.903472900390625\n",
      "Epoch [259/500], Training Loss: 35.7439\n",
      "Validation Loss: 34.0794, valid error: 34.49504470825195\n",
      "Epoch [260/500], Training Loss: 36.3210\n",
      "Validation Loss: 34.3994, valid error: 34.81645202636719\n",
      "Epoch [261/500], Training Loss: 36.3052\n",
      "Validation Loss: 34.5874, valid error: 35.0167236328125\n",
      "Epoch [262/500], Training Loss: 35.6277\n",
      "Validation Loss: 34.1990, valid error: 34.62082290649414\n",
      "Epoch [263/500], Training Loss: 34.8763\n",
      "Validation Loss: 34.1421, valid error: 34.569374084472656\n",
      "Epoch [264/500], Training Loss: 33.8675\n",
      "Validation Loss: 33.2780, valid error: 33.699092864990234\n",
      "Epoch [265/500], Training Loss: 33.5343\n",
      "Validation Loss: 32.6296, valid error: 33.044124603271484\n",
      "Epoch [266/500], Training Loss: 33.3329\n",
      "Validation Loss: 32.7664, valid error: 33.182315826416016\n",
      "Epoch [267/500], Training Loss: 32.7628\n",
      "Validation Loss: 32.2042, valid error: 32.61800765991211\n",
      "Epoch [268/500], Training Loss: 32.4175\n",
      "Validation Loss: 31.7444, valid error: 32.15794372558594\n",
      "Epoch [269/500], Training Loss: 32.2169\n",
      "Validation Loss: 32.0525, valid error: 32.46466827392578\n",
      "Epoch [270/500], Training Loss: 31.7068\n",
      "Validation Loss: 32.2850, valid error: 32.69757843017578\n",
      "Epoch [271/500], Training Loss: 31.4112\n",
      "Validation Loss: 31.8931, valid error: 32.30792236328125\n",
      "Epoch [272/500], Training Loss: 31.2448\n",
      "Validation Loss: 31.6978, valid error: 32.11241149902344\n",
      "Epoch [273/500], Training Loss: 31.0900\n",
      "Validation Loss: 31.7809, valid error: 32.19232177734375\n",
      "Epoch [274/500], Training Loss: 30.8963\n",
      "Validation Loss: 32.0023, valid error: 32.41230010986328\n",
      "Epoch [275/500], Training Loss: 31.2702\n",
      "Validation Loss: 31.5290, valid error: 31.941608428955078\n",
      "Epoch [276/500], Training Loss: 31.6885\n",
      "Validation Loss: 32.3839, valid error: 32.79646301269531\n",
      "Epoch [277/500], Training Loss: 32.0412\n",
      "Validation Loss: 32.6862, valid error: 33.107967376708984\n",
      "Epoch [278/500], Training Loss: 31.0518\n",
      "Validation Loss: 32.4336, valid error: 32.84659194946289\n",
      "Epoch [279/500], Training Loss: 32.8149\n",
      "Validation Loss: 32.3085, valid error: 32.72566604614258\n",
      "Epoch [280/500], Training Loss: 31.3385\n",
      "Validation Loss: 31.7843, valid error: 32.2010612487793\n",
      "Epoch [281/500], Training Loss: 30.3300\n",
      "Validation Loss: 32.9895, valid error: 33.40432357788086\n",
      "Epoch [282/500], Training Loss: 30.1874\n",
      "Validation Loss: 32.5155, valid error: 32.9295768737793\n",
      "Epoch [283/500], Training Loss: 29.4890\n",
      "Validation Loss: 32.7113, valid error: 33.12468719482422\n",
      "Epoch [284/500], Training Loss: 29.4321\n",
      "Validation Loss: 32.6767, valid error: 33.086509704589844\n",
      "Epoch [285/500], Training Loss: 29.3657\n",
      "Validation Loss: 33.0783, valid error: 33.491172790527344\n",
      "Epoch [286/500], Training Loss: 29.2046\n",
      "Validation Loss: 33.7728, valid error: 34.18532943725586\n",
      "Epoch [287/500], Training Loss: 29.2078\n",
      "Validation Loss: 33.4338, valid error: 33.844764709472656\n",
      "Epoch [288/500], Training Loss: 29.7254\n",
      "Validation Loss: 32.2139, valid error: 32.62787628173828\n",
      "Epoch [289/500], Training Loss: 29.4290\n",
      "Validation Loss: 33.3756, valid error: 33.78819274902344\n",
      "Epoch [290/500], Training Loss: 29.1066\n",
      "Validation Loss: 32.5191, valid error: 32.93147277832031\n",
      "Epoch [291/500], Training Loss: 29.1975\n",
      "Validation Loss: 33.9828, valid error: 34.39960479736328\n",
      "Epoch [292/500], Training Loss: 29.1253\n",
      "Validation Loss: 32.9960, valid error: 33.40732192993164\n",
      "Epoch [293/500], Training Loss: 28.6835\n",
      "Validation Loss: 34.4112, valid error: 34.82335662841797\n",
      "Epoch [294/500], Training Loss: 29.0189\n",
      "Validation Loss: 33.9921, valid error: 34.40393829345703\n",
      "Epoch [295/500], Training Loss: 28.4645\n",
      "Validation Loss: 36.0493, valid error: 36.464195251464844\n",
      "Epoch [296/500], Training Loss: 28.4199\n",
      "Validation Loss: 33.5719, valid error: 33.98563766479492\n",
      "Epoch [297/500], Training Loss: 28.7216\n",
      "Validation Loss: 31.3706, valid error: 31.781225204467773\n",
      "Epoch [298/500], Training Loss: 28.3379\n",
      "Validation Loss: 30.8433, valid error: 31.254310607910156\n",
      "Epoch [299/500], Training Loss: 28.7060\n",
      "Validation Loss: 28.9806, valid error: 29.389892578125\n",
      "Epoch [300/500], Training Loss: 27.4776\n",
      "Validation Loss: 28.2169, valid error: 28.626977920532227\n",
      "Epoch [301/500], Training Loss: 27.2729\n",
      "Validation Loss: 28.3562, valid error: 28.76610565185547\n",
      "Epoch [302/500], Training Loss: 26.6743\n",
      "Validation Loss: 29.4711, valid error: 29.884368896484375\n",
      "Epoch [303/500], Training Loss: 26.5420\n",
      "Validation Loss: 29.4348, valid error: 29.84531021118164\n",
      "Epoch [304/500], Training Loss: 25.9700\n",
      "Validation Loss: 29.3461, valid error: 29.75640869140625\n",
      "Epoch [305/500], Training Loss: 25.2876\n",
      "Validation Loss: 28.7257, valid error: 29.134143829345703\n",
      "Epoch [306/500], Training Loss: 24.9687\n",
      "Validation Loss: 28.9416, valid error: 29.35196304321289\n",
      "Epoch [307/500], Training Loss: 24.5515\n",
      "Validation Loss: 28.5262, valid error: 28.93501091003418\n",
      "Epoch [308/500], Training Loss: 24.0632\n",
      "Validation Loss: 27.6677, valid error: 28.077726364135742\n",
      "Epoch [309/500], Training Loss: 23.7633\n",
      "Validation Loss: 27.4518, valid error: 27.864131927490234\n",
      "Epoch [310/500], Training Loss: 23.4981\n",
      "Validation Loss: 27.4488, valid error: 27.858680725097656\n",
      "Epoch [311/500], Training Loss: 23.1872\n",
      "Validation Loss: 27.1640, valid error: 27.580665588378906\n",
      "Epoch [312/500], Training Loss: 22.9921\n",
      "Validation Loss: 26.6959, valid error: 27.104995727539062\n",
      "Epoch [313/500], Training Loss: 22.7228\n",
      "Validation Loss: 26.6330, valid error: 27.046527862548828\n",
      "Epoch [314/500], Training Loss: 22.8292\n",
      "Validation Loss: 26.4404, valid error: 26.852270126342773\n",
      "Epoch [315/500], Training Loss: 22.5475\n",
      "Validation Loss: 26.0794, valid error: 26.49386978149414\n",
      "Epoch [316/500], Training Loss: 22.6178\n",
      "Validation Loss: 25.5552, valid error: 25.968097686767578\n",
      "Epoch [317/500], Training Loss: 22.8644\n",
      "Validation Loss: 25.8904, valid error: 26.301816940307617\n",
      "Epoch [318/500], Training Loss: 23.1822\n",
      "Validation Loss: 25.8563, valid error: 26.26657485961914\n",
      "Epoch [319/500], Training Loss: 22.9078\n",
      "Validation Loss: 26.3041, valid error: 26.71976089477539\n",
      "Epoch [320/500], Training Loss: 23.0040\n",
      "Validation Loss: 26.3961, valid error: 26.810165405273438\n",
      "Epoch [321/500], Training Loss: 24.9870\n",
      "Validation Loss: 26.5472, valid error: 26.963417053222656\n",
      "Epoch [322/500], Training Loss: 23.8829\n",
      "Validation Loss: 25.6573, valid error: 26.078845977783203\n",
      "Epoch [323/500], Training Loss: 23.0067\n",
      "Validation Loss: 25.7749, valid error: 26.190309524536133\n",
      "Epoch [324/500], Training Loss: 22.7057\n",
      "Validation Loss: 25.5531, valid error: 25.967723846435547\n",
      "Epoch [325/500], Training Loss: 21.6614\n",
      "Validation Loss: 25.2382, valid error: 25.650390625\n",
      "Epoch [326/500], Training Loss: 21.3963\n",
      "Validation Loss: 25.2783, valid error: 25.687732696533203\n",
      "Epoch [327/500], Training Loss: 21.0939\n",
      "Validation Loss: 24.8708, valid error: 25.28268051147461\n",
      "Epoch [328/500], Training Loss: 20.8235\n",
      "Validation Loss: 24.7463, valid error: 25.15703582763672\n",
      "Epoch [329/500], Training Loss: 20.5952\n",
      "Validation Loss: 24.4687, valid error: 24.881017684936523\n",
      "Epoch [330/500], Training Loss: 20.8108\n",
      "Validation Loss: 25.3546, valid error: 25.765148162841797\n",
      "Epoch [331/500], Training Loss: 20.7729\n",
      "Validation Loss: 25.3811, valid error: 25.791475296020508\n",
      "Epoch [332/500], Training Loss: 20.5811\n",
      "Validation Loss: 25.9059, valid error: 26.318035125732422\n",
      "Epoch [333/500], Training Loss: 20.9283\n",
      "Validation Loss: 25.9301, valid error: 26.343881607055664\n",
      "Epoch [334/500], Training Loss: 20.5101\n",
      "Validation Loss: 25.8724, valid error: 26.283187866210938\n",
      "Epoch [335/500], Training Loss: 20.8183\n",
      "Validation Loss: 24.7193, valid error: 25.128192901611328\n",
      "Epoch [336/500], Training Loss: 21.0562\n",
      "Validation Loss: 24.5095, valid error: 24.92006492614746\n",
      "Epoch [337/500], Training Loss: 20.6052\n",
      "Validation Loss: 24.8721, valid error: 25.283151626586914\n",
      "Epoch [338/500], Training Loss: 20.0665\n",
      "Validation Loss: 25.0324, valid error: 25.442434310913086\n",
      "Epoch [339/500], Training Loss: 20.0727\n",
      "Validation Loss: 24.2983, valid error: 24.718128204345703\n",
      "Epoch [340/500], Training Loss: 20.4209\n",
      "Validation Loss: 23.6797, valid error: 24.09122085571289\n",
      "Epoch [341/500], Training Loss: 19.9926\n",
      "Validation Loss: 24.5349, valid error: 24.953887939453125\n",
      "Epoch [342/500], Training Loss: 19.6090\n",
      "Validation Loss: 23.4888, valid error: 23.90325927734375\n",
      "Epoch [343/500], Training Loss: 19.4701\n",
      "Validation Loss: 23.1604, valid error: 23.571548461914062\n",
      "Epoch [344/500], Training Loss: 19.3774\n",
      "Validation Loss: 23.1620, valid error: 23.572431564331055\n",
      "Epoch [345/500], Training Loss: 19.2135\n",
      "Validation Loss: 23.3085, valid error: 23.717872619628906\n",
      "Epoch [346/500], Training Loss: 18.7627\n",
      "Validation Loss: 23.1660, valid error: 23.576744079589844\n",
      "Epoch [347/500], Training Loss: 18.4094\n",
      "Validation Loss: 23.7531, valid error: 24.16305923461914\n",
      "Epoch [348/500], Training Loss: 18.5053\n",
      "Validation Loss: 23.6399, valid error: 24.050403594970703\n",
      "Epoch [349/500], Training Loss: 18.7471\n",
      "Validation Loss: 24.3852, valid error: 24.79855728149414\n",
      "Epoch [350/500], Training Loss: 18.9269\n",
      "Validation Loss: 23.9736, valid error: 24.386226654052734\n",
      "Epoch [351/500], Training Loss: 19.0186\n",
      "Validation Loss: 22.5570, valid error: 22.96746253967285\n",
      "Epoch [352/500], Training Loss: 19.6057\n",
      "Validation Loss: 22.9647, valid error: 23.37712860107422\n",
      "Epoch [353/500], Training Loss: 19.3647\n",
      "Validation Loss: 24.0426, valid error: 24.4550724029541\n",
      "Epoch [354/500], Training Loss: 18.6243\n",
      "Validation Loss: 23.8732, valid error: 24.28666877746582\n",
      "Epoch [355/500], Training Loss: 18.3398\n",
      "Validation Loss: 23.7890, valid error: 24.197513580322266\n",
      "Epoch [356/500], Training Loss: 17.9911\n",
      "Validation Loss: 22.9765, valid error: 23.390636444091797\n",
      "Epoch [357/500], Training Loss: 17.8082\n",
      "Validation Loss: 22.7699, valid error: 23.181663513183594\n",
      "Epoch [358/500], Training Loss: 18.1029\n",
      "Validation Loss: 22.6083, valid error: 23.020431518554688\n",
      "Epoch [359/500], Training Loss: 18.5753\n",
      "Validation Loss: 23.7671, valid error: 24.175922393798828\n",
      "Epoch [360/500], Training Loss: 17.9403\n",
      "Validation Loss: 23.6541, valid error: 24.06941032409668\n",
      "Epoch [361/500], Training Loss: 18.7925\n",
      "Validation Loss: 23.2875, valid error: 23.700790405273438\n",
      "Epoch [362/500], Training Loss: 17.8325\n",
      "Validation Loss: 23.2598, valid error: 23.67519187927246\n",
      "Epoch [363/500], Training Loss: 17.8005\n",
      "Validation Loss: 22.3152, valid error: 22.725276947021484\n",
      "Epoch [364/500], Training Loss: 17.9895\n",
      "Validation Loss: 22.3056, valid error: 22.714595794677734\n",
      "Epoch [365/500], Training Loss: 17.8133\n",
      "Validation Loss: 22.8242, valid error: 23.239849090576172\n",
      "Epoch [366/500], Training Loss: 17.8332\n",
      "Validation Loss: 22.3233, valid error: 22.734207153320312\n",
      "Epoch [367/500], Training Loss: 17.3289\n",
      "Validation Loss: 21.7599, valid error: 22.17762565612793\n",
      "Epoch [368/500], Training Loss: 16.9118\n",
      "Validation Loss: 21.7098, valid error: 22.122142791748047\n",
      "Epoch [369/500], Training Loss: 17.5598\n",
      "Validation Loss: 22.3327, valid error: 22.74374771118164\n",
      "Epoch [370/500], Training Loss: 17.1561\n",
      "Validation Loss: 22.2948, valid error: 22.710918426513672\n",
      "Epoch [371/500], Training Loss: 16.8246\n",
      "Validation Loss: 22.0026, valid error: 22.42244529724121\n",
      "Epoch [372/500], Training Loss: 16.3939\n",
      "Validation Loss: 21.8284, valid error: 22.242809295654297\n",
      "Epoch [373/500], Training Loss: 16.0468\n",
      "Validation Loss: 21.4268, valid error: 21.841144561767578\n",
      "Epoch [374/500], Training Loss: 16.2061\n",
      "Validation Loss: 20.9847, valid error: 21.39366912841797\n",
      "Epoch [375/500], Training Loss: 16.7592\n",
      "Validation Loss: 21.6448, valid error: 22.05682373046875\n",
      "Epoch [376/500], Training Loss: 16.7297\n",
      "Validation Loss: 21.8736, valid error: 22.28382110595703\n",
      "Epoch [377/500], Training Loss: 16.4611\n",
      "Validation Loss: 22.0701, valid error: 22.483135223388672\n",
      "Epoch [378/500], Training Loss: 16.5932\n",
      "Validation Loss: 21.8018, valid error: 22.212114334106445\n",
      "Epoch [379/500], Training Loss: 16.3406\n",
      "Validation Loss: 21.1766, valid error: 21.588918685913086\n",
      "Epoch [380/500], Training Loss: 16.2398\n",
      "Validation Loss: 20.7158, valid error: 21.129531860351562\n",
      "Epoch [381/500], Training Loss: 16.8219\n",
      "Validation Loss: 21.3117, valid error: 21.719295501708984\n",
      "Epoch [382/500], Training Loss: 16.9013\n",
      "Validation Loss: 21.4970, valid error: 21.91107749938965\n",
      "Epoch [383/500], Training Loss: 16.4889\n",
      "Validation Loss: 21.5665, valid error: 21.9783878326416\n",
      "Epoch [384/500], Training Loss: 16.8011\n",
      "Validation Loss: 21.6224, valid error: 22.0382080078125\n",
      "Epoch [385/500], Training Loss: 16.3395\n",
      "Validation Loss: 21.1386, valid error: 21.551746368408203\n",
      "Epoch [386/500], Training Loss: 16.5922\n",
      "Validation Loss: 20.3300, valid error: 20.737972259521484\n",
      "Epoch [387/500], Training Loss: 16.3847\n",
      "Validation Loss: 21.4582, valid error: 21.872318267822266\n",
      "Epoch [388/500], Training Loss: 15.8221\n",
      "Validation Loss: 21.6017, valid error: 22.015714645385742\n",
      "Epoch [389/500], Training Loss: 16.0216\n",
      "Validation Loss: 21.4212, valid error: 21.83293342590332\n",
      "Epoch [390/500], Training Loss: 15.5893\n",
      "Validation Loss: 20.7003, valid error: 21.110610961914062\n",
      "Epoch [391/500], Training Loss: 15.4977\n",
      "Validation Loss: 20.4313, valid error: 20.8427677154541\n",
      "Epoch [392/500], Training Loss: 15.5129\n",
      "Validation Loss: 20.2732, valid error: 20.6822509765625\n",
      "Epoch [393/500], Training Loss: 15.2336\n",
      "Validation Loss: 21.4112, valid error: 21.825775146484375\n",
      "Epoch [394/500], Training Loss: 15.6803\n",
      "Validation Loss: 21.1400, valid error: 21.55245590209961\n",
      "Epoch [395/500], Training Loss: 15.5036\n",
      "Validation Loss: 20.3882, valid error: 20.798276901245117\n",
      "Epoch [396/500], Training Loss: 15.5910\n",
      "Validation Loss: 20.1067, valid error: 20.515621185302734\n",
      "Epoch [397/500], Training Loss: 15.9098\n",
      "Validation Loss: 21.2831, valid error: 21.694580078125\n",
      "Epoch [398/500], Training Loss: 15.1555\n",
      "Validation Loss: 20.7108, valid error: 21.13286781311035\n",
      "Epoch [399/500], Training Loss: 15.3582\n",
      "Validation Loss: 21.8570, valid error: 22.269268035888672\n",
      "Epoch [400/500], Training Loss: 15.0785\n",
      "Validation Loss: 20.4473, valid error: 20.860477447509766\n",
      "Epoch [401/500], Training Loss: 14.8796\n",
      "Validation Loss: 20.2109, valid error: 20.621185302734375\n",
      "Epoch [402/500], Training Loss: 15.5866\n",
      "Validation Loss: 20.4127, valid error: 20.822265625\n",
      "Epoch [403/500], Training Loss: 14.7849\n",
      "Validation Loss: 20.4461, valid error: 20.859880447387695\n",
      "Epoch [404/500], Training Loss: 15.2187\n",
      "Validation Loss: 20.8018, valid error: 21.21332550048828\n",
      "Epoch [405/500], Training Loss: 14.9353\n",
      "Validation Loss: 19.9845, valid error: 20.395050048828125\n",
      "Epoch [406/500], Training Loss: 15.3698\n",
      "Validation Loss: 20.1130, valid error: 20.52184295654297\n",
      "Epoch [407/500], Training Loss: 15.8117\n",
      "Validation Loss: 20.6902, valid error: 21.103302001953125\n",
      "Epoch [408/500], Training Loss: 16.1423\n",
      "Validation Loss: 20.6135, valid error: 21.028993606567383\n",
      "Epoch [409/500], Training Loss: 15.7388\n",
      "Validation Loss: 20.9882, valid error: 21.399799346923828\n",
      "Epoch [410/500], Training Loss: 14.9466\n",
      "Validation Loss: 19.4878, valid error: 19.897974014282227\n",
      "Epoch [411/500], Training Loss: 15.1657\n",
      "Validation Loss: 20.4605, valid error: 20.87310028076172\n",
      "Epoch [412/500], Training Loss: 14.7532\n",
      "Validation Loss: 20.1920, valid error: 20.603466033935547\n",
      "Epoch [413/500], Training Loss: 14.5808\n",
      "Validation Loss: 20.1279, valid error: 20.53969383239746\n",
      "Epoch [414/500], Training Loss: 14.1770\n",
      "Validation Loss: 19.5889, valid error: 19.99789810180664\n",
      "Epoch [415/500], Training Loss: 14.8791\n",
      "Validation Loss: 20.0397, valid error: 20.450519561767578\n",
      "Epoch [416/500], Training Loss: 14.3418\n",
      "Validation Loss: 20.1644, valid error: 20.586257934570312\n",
      "Epoch [417/500], Training Loss: 14.2648\n",
      "Validation Loss: 20.0468, valid error: 20.459712982177734\n",
      "Epoch [418/500], Training Loss: 14.1676\n",
      "Validation Loss: 19.5486, valid error: 19.959421157836914\n",
      "Epoch [419/500], Training Loss: 13.8307\n",
      "Validation Loss: 18.9817, valid error: 19.391780853271484\n",
      "Epoch [420/500], Training Loss: 14.5091\n",
      "Validation Loss: 19.9601, valid error: 20.37653350830078\n",
      "Epoch [421/500], Training Loss: 14.0177\n",
      "Validation Loss: 20.2871, valid error: 20.698881149291992\n",
      "Epoch [422/500], Training Loss: 14.1350\n",
      "Validation Loss: 19.5628, valid error: 19.9752140045166\n",
      "Epoch [423/500], Training Loss: 14.1825\n",
      "Validation Loss: 20.1978, valid error: 20.608325958251953\n",
      "Epoch [424/500], Training Loss: 13.9962\n",
      "Validation Loss: 19.1695, valid error: 19.580745697021484\n",
      "Epoch [425/500], Training Loss: 14.5444\n",
      "Validation Loss: 19.7411, valid error: 20.153118133544922\n",
      "Epoch [426/500], Training Loss: 14.0463\n",
      "Validation Loss: 19.7485, valid error: 20.157264709472656\n",
      "Epoch [427/500], Training Loss: 14.2467\n",
      "Validation Loss: 20.0527, valid error: 20.464099884033203\n",
      "Epoch [428/500], Training Loss: 13.6319\n",
      "Validation Loss: 19.0562, valid error: 19.465816497802734\n",
      "Epoch [429/500], Training Loss: 14.1905\n",
      "Validation Loss: 19.1101, valid error: 19.51961326599121\n",
      "Epoch [430/500], Training Loss: 14.5783\n",
      "Validation Loss: 19.8969, valid error: 20.312522888183594\n",
      "Epoch [431/500], Training Loss: 14.5207\n",
      "Validation Loss: 19.7422, valid error: 20.15481185913086\n",
      "Epoch [432/500], Training Loss: 14.1891\n",
      "Validation Loss: 19.6509, valid error: 20.06173324584961\n",
      "Epoch [433/500], Training Loss: 14.1710\n",
      "Validation Loss: 19.2103, valid error: 19.619604110717773\n",
      "Epoch [434/500], Training Loss: 14.1459\n",
      "Validation Loss: 19.8860, valid error: 20.29787826538086\n",
      "Epoch [435/500], Training Loss: 14.0610\n",
      "Validation Loss: 19.9068, valid error: 20.317241668701172\n",
      "Epoch [436/500], Training Loss: 13.6946\n",
      "Validation Loss: 19.0591, valid error: 19.475976943969727\n",
      "Epoch [437/500], Training Loss: 13.6859\n",
      "Validation Loss: 19.3829, valid error: 19.791309356689453\n",
      "Epoch [438/500], Training Loss: 13.3713\n",
      "Validation Loss: 18.8067, valid error: 19.225961685180664\n",
      "Epoch [439/500], Training Loss: 12.9988\n",
      "Validation Loss: 19.8460, valid error: 20.259233474731445\n",
      "Epoch [440/500], Training Loss: 13.1074\n",
      "Validation Loss: 18.7592, valid error: 19.16986083984375\n",
      "Epoch [441/500], Training Loss: 12.7391\n",
      "Validation Loss: 18.9557, valid error: 19.36762237548828\n",
      "Epoch [442/500], Training Loss: 12.9508\n",
      "Validation Loss: 18.6112, valid error: 19.019655227661133\n",
      "Epoch [443/500], Training Loss: 13.0171\n",
      "Validation Loss: 19.4668, valid error: 19.877599716186523\n",
      "Epoch [444/500], Training Loss: 13.4191\n",
      "Validation Loss: 19.0184, valid error: 19.432649612426758\n",
      "Epoch [445/500], Training Loss: 13.8161\n",
      "Validation Loss: 19.4184, valid error: 19.833553314208984\n",
      "Epoch [446/500], Training Loss: 13.3013\n",
      "Validation Loss: 19.1251, valid error: 19.534494400024414\n",
      "Epoch [447/500], Training Loss: 14.2643\n",
      "Validation Loss: 19.3190, valid error: 19.72791290283203\n",
      "Epoch [448/500], Training Loss: 13.4598\n",
      "Validation Loss: 19.5200, valid error: 19.93681526184082\n",
      "Epoch [449/500], Training Loss: 13.2911\n",
      "Validation Loss: 19.1356, valid error: 19.547744750976562\n",
      "Epoch [450/500], Training Loss: 12.8234\n",
      "Validation Loss: 18.5842, valid error: 18.994220733642578\n",
      "Epoch [451/500], Training Loss: 13.1189\n",
      "Validation Loss: 19.0979, valid error: 19.507905960083008\n",
      "Epoch [452/500], Training Loss: 12.9463\n",
      "Validation Loss: 18.3722, valid error: 18.788007736206055\n",
      "Epoch [453/500], Training Loss: 12.9598\n",
      "Validation Loss: 18.9390, valid error: 19.350805282592773\n",
      "Epoch [454/500], Training Loss: 12.7893\n",
      "Validation Loss: 18.5774, valid error: 18.989604949951172\n",
      "Epoch [455/500], Training Loss: 12.8234\n",
      "Validation Loss: 18.7493, valid error: 19.16144371032715\n",
      "Epoch [456/500], Training Loss: 13.4473\n",
      "Validation Loss: 19.0922, valid error: 19.509750366210938\n",
      "Epoch [457/500], Training Loss: 13.2820\n",
      "Validation Loss: 19.2181, valid error: 19.62916374206543\n",
      "Epoch [458/500], Training Loss: 13.0186\n",
      "Validation Loss: 18.4390, valid error: 18.85155487060547\n",
      "Epoch [459/500], Training Loss: 12.7944\n",
      "Validation Loss: 18.2208, valid error: 18.63079833984375\n",
      "Epoch [460/500], Training Loss: 12.7872\n",
      "Validation Loss: 18.1232, valid error: 18.531009674072266\n",
      "Epoch [461/500], Training Loss: 13.2627\n",
      "Validation Loss: 18.5704, valid error: 18.97906494140625\n",
      "Epoch [462/500], Training Loss: 13.2845\n",
      "Validation Loss: 18.7957, valid error: 19.206527709960938\n",
      "Epoch [463/500], Training Loss: 13.5094\n",
      "Validation Loss: 18.5615, valid error: 18.970691680908203\n",
      "Epoch [464/500], Training Loss: 12.8968\n",
      "Validation Loss: 17.9478, valid error: 18.355850219726562\n",
      "Epoch [465/500], Training Loss: 13.4528\n",
      "Validation Loss: 18.6125, valid error: 19.02074432373047\n",
      "Epoch [466/500], Training Loss: 12.8949\n",
      "Validation Loss: 18.0575, valid error: 18.46786117553711\n",
      "Epoch [467/500], Training Loss: 12.3600\n",
      "Validation Loss: 18.2917, valid error: 18.70083999633789\n",
      "Epoch [468/500], Training Loss: 12.2644\n",
      "Validation Loss: 18.3661, valid error: 18.77100372314453\n",
      "Epoch [469/500], Training Loss: 12.3398\n",
      "Validation Loss: 17.8618, valid error: 18.26612091064453\n",
      "Epoch [470/500], Training Loss: 12.6999\n",
      "Validation Loss: 18.2644, valid error: 18.670413970947266\n",
      "Epoch [471/500], Training Loss: 12.4045\n",
      "Validation Loss: 18.4622, valid error: 18.86640739440918\n",
      "Epoch [472/500], Training Loss: 13.1473\n",
      "Validation Loss: 19.2302, valid error: 19.63697624206543\n",
      "Epoch [473/500], Training Loss: 12.9122\n",
      "Validation Loss: 18.3018, valid error: 18.708219528198242\n",
      "Epoch [474/500], Training Loss: 13.2956\n",
      "Validation Loss: 18.1610, valid error: 18.565025329589844\n",
      "Epoch [475/500], Training Loss: 13.1268\n",
      "Validation Loss: 18.7596, valid error: 19.16747283935547\n",
      "Epoch [476/500], Training Loss: 13.4671\n",
      "Validation Loss: 18.9938, valid error: 19.398935317993164\n",
      "Epoch [477/500], Training Loss: 13.2674\n",
      "Validation Loss: 17.9541, valid error: 18.356246948242188\n",
      "Epoch [478/500], Training Loss: 13.4638\n",
      "Validation Loss: 18.1784, valid error: 18.57944107055664\n",
      "Epoch [479/500], Training Loss: 12.5845\n",
      "Validation Loss: 18.2324, valid error: 18.637128829956055\n",
      "Epoch [480/500], Training Loss: 12.9647\n",
      "Validation Loss: 19.0708, valid error: 19.477375030517578\n",
      "Epoch [481/500], Training Loss: 12.5979\n",
      "Validation Loss: 17.6908, valid error: 18.091842651367188\n",
      "Epoch [482/500], Training Loss: 12.3308\n",
      "Validation Loss: 18.3352, valid error: 18.732479095458984\n",
      "Epoch [483/500], Training Loss: 12.0815\n",
      "Validation Loss: 18.3575, valid error: 18.75574493408203\n",
      "Epoch [484/500], Training Loss: 12.1980\n",
      "Validation Loss: 18.2716, valid error: 18.665966033935547\n",
      "Epoch [485/500], Training Loss: 12.0732\n",
      "Validation Loss: 19.0265, valid error: 19.42449188232422\n",
      "Epoch [486/500], Training Loss: 12.3891\n",
      "Validation Loss: 18.0214, valid error: 18.417865753173828\n",
      "Epoch [487/500], Training Loss: 12.5827\n",
      "Validation Loss: 18.8766, valid error: 19.281471252441406\n",
      "Epoch [488/500], Training Loss: 12.5812\n",
      "Validation Loss: 18.2601, valid error: 18.65591049194336\n",
      "Epoch [489/500], Training Loss: 12.5443\n",
      "Validation Loss: 18.1526, valid error: 18.545337677001953\n",
      "Epoch [490/500], Training Loss: 12.3720\n",
      "Validation Loss: 18.0088, valid error: 18.400815963745117\n",
      "Epoch [491/500], Training Loss: 12.4460\n",
      "Validation Loss: 18.5196, valid error: 18.926509857177734\n",
      "Epoch [492/500], Training Loss: 12.0831\n",
      "Validation Loss: 18.2420, valid error: 18.63128662109375\n",
      "Epoch [493/500], Training Loss: 12.0899\n",
      "Validation Loss: 17.8569, valid error: 18.245227813720703\n",
      "Epoch [494/500], Training Loss: 11.8507\n",
      "Validation Loss: 18.1253, valid error: 18.512100219726562\n",
      "Epoch [495/500], Training Loss: 12.1680\n",
      "Validation Loss: 18.2864, valid error: 18.68242645263672\n",
      "Epoch [496/500], Training Loss: 11.9129\n",
      "Validation Loss: 18.0414, valid error: 18.428552627563477\n",
      "Epoch [497/500], Training Loss: 11.5577\n",
      "Validation Loss: 17.8970, valid error: 18.280969619750977\n",
      "Epoch [498/500], Training Loss: 11.3911\n",
      "Validation Loss: 17.6013, valid error: 17.984935760498047\n",
      "Epoch [499/500], Training Loss: 11.4430\n",
      "Validation Loss: 17.9230, valid error: 18.307353973388672\n",
      "Epoch [500/500], Training Loss: 11.6508\n",
      "Validation Loss: 17.8186, valid error: 18.204387664794922\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(256, 1, input_dim=5)\n",
    "train_length, valid_length = len(batch_train_data), len(batch_valid_data)\n",
    "train_model(model, train_loader, valid_loader, train_length, valid_length, 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE\n",
      "13.43122487478052 125543\n",
      "valid MAE\n",
      "24.77413183874909 6147\n"
     ]
    }
   ],
   "source": [
    "def show(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    data_num = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in loader:\n",
    "            inputs, lengths = inputs.to(device, dtype=torch.float32), lengths.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "            outputs, _ = model(inputs, hidden, lengths)\n",
    "            outputs = outputs.to('cpu', dtype=torch.float32).view(labels.shape[0], -1)\n",
    "\n",
    "            \n",
    "            for i in range(labels.shape[0]):\n",
    "                length = lengths[i]\n",
    "                error += abs(outputs[i, :length] - labels[i, :length]).sum()\n",
    "                data_num += length\n",
    "\n",
    "    print(float(error) / int(data_num), int(data_num))\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(\"train MAE\")\n",
    "show(model, train_loader, device)\n",
    "print(\"valid MAE\")\n",
    "show(model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
