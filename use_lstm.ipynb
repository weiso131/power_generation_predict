{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from utils.csv_to_pd import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:14:06.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.48</td>\n",
       "      <td>15.59</td>\n",
       "      <td>94.3</td>\n",
       "      <td>652.92</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationCode                 DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0            10  2024-03-01 17:14:06.000             0.0        1017.48   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0            15.59         94.3         652.92       0.12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dir_csv()\n",
    "\n",
    "location_ori = list(df[\"LocationCode\"]) \n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00          10.0        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  hour  \n",
       "0        15.712857    93.771429     652.797143   0.115714    17  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mean_10min(df)\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>171.555961</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>2.273539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00    171.555961        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)      hour  \n",
       "0        15.712857    93.771429     652.797143   0.115714  2.273539  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=[\"LocationCode\", \"hour\"], sigma = 0.05)\n",
    "encoder.fit(df, df['Power(mW)'])\n",
    "df = encoder.transform(df)\n",
    "\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "      <th>hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>-0.757742</td>\n",
       "      <td>-0.284717</td>\n",
       "      <td>0.741951</td>\n",
       "      <td>-1.640724</td>\n",
       "      <td>0.974532</td>\n",
       "      <td>-0.721713</td>\n",
       "      <td>0.115714</td>\n",
       "      <td>-1.015733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00     -0.757742       -0.284717       0.741951   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)      hour  \n",
       "0        -1.640724     0.974532      -0.721713   0.115714 -1.015733  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定要標準化的欄位\n",
    "columns_to_standardize = ['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)', \"LocationCode\", \"hour\"]\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 對指定欄位進行標準化\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def split_data_random(data_label_list, train_ratio=0.95):\n",
    "\n",
    "    # 創建索引列表並隨機打亂\n",
    "    indices = list(range(len(data_label_list)))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # 計算分割點\n",
    "    train_size = int(len(data_label_list) * train_ratio)\n",
    "\n",
    "    # 分配數據\n",
    "    train_indices = indices[:train_size]\n",
    "    valid_indices = indices[train_size:]\n",
    "\n",
    "    # 根據索引分割數據\n",
    "    train_data_label_list = [data_label_list[i] for i in train_indices]\n",
    "    valid_data_label_list = [data_label_list[i] for i in valid_indices]\n",
    "\n",
    "\n",
    "    return train_data_label_list, valid_data_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label_list, _ = spilt_data_with_datetime(df, location_ori)\n",
    "\n",
    "train_data_label_list, valid_data_label_list = split_data_random(data_label_list)\n",
    "\n",
    "train_data, train_label, train_length = sort_by_length(train_data_label_list)\n",
    "valid_data, valid_label, valid_length = sort_by_length(valid_data_label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def padding(data_list, label_list, length, batch=64):\n",
    "\n",
    "    batch_data_list = []\n",
    "    batch_label_list = []\n",
    "    batch_length = []\n",
    "\n",
    "    for i in range(0, len(data_list), batch):\n",
    "        upper = min(len(data_list), i + batch)\n",
    "        data = pad_sequence(data_list[i:upper], batch_first=True, padding_value=0)\n",
    "        label = pad_sequence(label_list[i:upper], batch_first=True, padding_value=0)\n",
    "        batch_data_list.append(data)\n",
    "        batch_label_list.append(label)\n",
    "        batch_length.append(length[i:upper])\n",
    "    return batch_data_list, batch_label_list, batch_length\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 86, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "batch_train_data, batch_train_label, batch_train_length = padding(train_data, train_label, train_length)\n",
    "batch_valid_data, batch_valid_label, batch_valid_length = padding(valid_data, valid_label, valid_length)\n",
    "\n",
    "batch_train_data[-1].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((25430, 5, 5), (25430, 5))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def slice_seq_to_same_length(datas: list, labels: list, length: int):\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "    test_data = []\n",
    "    test_label = []\n",
    "\n",
    "    for i in range(len(datas)):\n",
    "        data = datas[i]\n",
    "        label = labels[i]\n",
    "        start = 0\n",
    "        end = len(data)\n",
    "        while end - start >= length:\n",
    "            train_data.append(data[start:start + length])\n",
    "            train_label.append(label[start:start + length])\n",
    "            start += length\n",
    "        if start != end:\n",
    "            test_data.append(data[start:start + length])\n",
    "            test_label.append(label[start:start + length])\n",
    "    return np.array(train_data), np.array(train_label), np.array(test_data, dtype=object), np.array(test_label, dtype=object)\n",
    "\n",
    "\n",
    "train_data, train_label, test_data, test_label = slice_seq_to_same_length(data_list, label_list, 5)\n",
    "\n",
    "for data in train_data:\n",
    "    assert len(data) == 5\n",
    "\n",
    "train_data.shape, train_label.shape\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data shape: torch.Size([64, 5, 5]), Batch labels shape: torch.Size([64, 5])\n"
     ]
    }
   ],
   "source": [
    "# 將數據轉換為 PyTorch 張量\n",
    "train_data_tensor = torch.tensor(train_data, dtype=torch.float32)\n",
    "train_label_tensor = torch.tensor(train_label, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 建立 TensorDataset\n",
    "dataset = TensorDataset(train_data_tensor, train_label_tensor)\n",
    "\n",
    "train_size = int(0.9 * len(dataset))\n",
    "valid_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "\n",
    "# 建立 DataLoader\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 檢查形狀\n",
    "for batch_data, batch_labels in train_loader:\n",
    "    print(f\"Batch data shape: {batch_data.shape}, Batch labels shape: {batch_labels.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: torch.Size([1, 5]), Label shape: torch.Size([1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Local\\Temp\\ipykernel_17416\\2696224944.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_data]\n",
      "C:\\Users\\weiso131\\AppData\\Local\\Temp\\ipykernel_17416\\2696224944.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_label_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_label]\n"
     ]
    }
   ],
   "source": [
    "# 將數據轉換為 PyTorch 張量列表，保留每個序列的不同長度\n",
    "test_data_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_data]\n",
    "test_label_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_label]\n",
    "\n",
    "# 建立自定義 Dataset 用於處理不同長度的序列\n",
    "class TestDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "# 建立 Test Dataset 和 DataLoader\n",
    "test_dataset = TestDataset(test_data_tensors, test_label_tensors)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 檢查測試資料加載情況\n",
    "for data, label in test_loader:\n",
    "    print(f\"Data shape: {data[0].shape}, Label shape: {label[0].shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, tagset_size, input_dim=6):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM層，輸入維度為 input_dim，輸出維度為 hidden_dim\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # 線性層將 LSTM 的輸出映射到標籤空間\n",
    "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence, hidden):\n",
    "        # sentence 的形狀為 (batch_size, seq_len, input_dim)\n",
    "        # LSTM 層的輸出 lstm_out 形狀為 (batch_size, seq_len, hidden_dim)\n",
    "        # 並傳回更新後的隱藏狀態\n",
    "        lstm_out, hidden = self.lstm(sentence, hidden)\n",
    "\n",
    "        # 使用線性層將 LSTM 的輸出映射到標籤空間\n",
    "        tag_space = self.relu(self.linear(self.relu(lstm_out)))\n",
    "\n",
    "        # tag_space 的形狀為 (batch_size, seq_len, tagset_size)\n",
    "        return tag_space, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# 設置 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定義訓練函數\n",
    "def train_model(model, train_loader, valid_loader, num_epochs=10, learning_rate=0.001):\n",
    "    # 將模型移到 GPU\n",
    "    model = model.to(device, dtype=torch.float32)\n",
    "    # 使用 Adam 優化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # 定義損失函數\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for inputs, labels in train_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            # 清零梯度\n",
    "            optimizer.zero_grad()\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            # 更新參數\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss / len(train_loader):.4f}\")\n",
    "\n",
    "        # 驗證模型\n",
    "        valid_loss = validate_model(model, valid_loader, criterion)\n",
    "\n",
    "# 定義驗證函數\n",
    "def validate_model(model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    error = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            error += abs(outputs.view(-1) - labels.view(-1)).sum() / inputs.shape[0] / inputs.shape[1]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {total_loss / len(valid_loader):.4f}, valid error: {error / len(valid_loader)}\")\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Training Loss: 238.6369\n",
      "Validation Loss: 232.8065, valid error: 233.26675415039062\n",
      "Epoch [2/100], Training Loss: 217.8508\n",
      "Validation Loss: 214.7195, valid error: 215.1526336669922\n",
      "Epoch [3/100], Training Loss: 200.5550\n",
      "Validation Loss: 197.7458, valid error: 198.17459106445312\n",
      "Epoch [4/100], Training Loss: 184.9402\n",
      "Validation Loss: 182.2517, valid error: 182.684326171875\n",
      "Epoch [5/100], Training Loss: 170.7321\n",
      "Validation Loss: 168.0332, valid error: 168.45046997070312\n",
      "Epoch [6/100], Training Loss: 157.7387\n",
      "Validation Loss: 155.4504, valid error: 155.8552703857422\n",
      "Epoch [7/100], Training Loss: 146.1977\n",
      "Validation Loss: 144.1400, valid error: 144.5362548828125\n",
      "Epoch [8/100], Training Loss: 136.0700\n",
      "Validation Loss: 134.6623, valid error: 135.0569610595703\n",
      "Epoch [9/100], Training Loss: 126.7118\n",
      "Validation Loss: 124.9030, valid error: 125.29620361328125\n",
      "Epoch [10/100], Training Loss: 118.1098\n",
      "Validation Loss: 116.2618, valid error: 116.6490249633789\n",
      "Epoch [11/100], Training Loss: 110.3455\n",
      "Validation Loss: 109.2428, valid error: 109.63136291503906\n",
      "Epoch [12/100], Training Loss: 103.4356\n",
      "Validation Loss: 102.3183, valid error: 102.71114349365234\n",
      "Epoch [13/100], Training Loss: 96.7493\n",
      "Validation Loss: 95.1044, valid error: 95.48908996582031\n",
      "Epoch [14/100], Training Loss: 90.6503\n",
      "Validation Loss: 88.9788, valid error: 89.36569213867188\n",
      "Epoch [15/100], Training Loss: 85.0698\n",
      "Validation Loss: 84.3594, valid error: 84.75081634521484\n",
      "Epoch [16/100], Training Loss: 79.9296\n",
      "Validation Loss: 78.8960, valid error: 79.28143310546875\n",
      "Epoch [17/100], Training Loss: 75.2447\n",
      "Validation Loss: 74.5214, valid error: 74.9083480834961\n",
      "Epoch [18/100], Training Loss: 71.1526\n",
      "Validation Loss: 71.5266, valid error: 71.9198226928711\n",
      "Epoch [19/100], Training Loss: 67.2004\n",
      "Validation Loss: 67.4340, valid error: 67.8249740600586\n",
      "Epoch [20/100], Training Loss: 63.5928\n",
      "Validation Loss: 63.6221, valid error: 64.01460266113281\n",
      "Epoch [21/100], Training Loss: 60.4040\n",
      "Validation Loss: 61.4222, valid error: 61.81045150756836\n",
      "Epoch [22/100], Training Loss: 57.5497\n",
      "Validation Loss: 57.9566, valid error: 58.34528732299805\n",
      "Epoch [23/100], Training Loss: 55.0320\n",
      "Validation Loss: 56.2035, valid error: 56.59237289428711\n",
      "Epoch [24/100], Training Loss: 52.8766\n",
      "Validation Loss: 54.3665, valid error: 54.754486083984375\n",
      "Epoch [25/100], Training Loss: 50.9165\n",
      "Validation Loss: 53.2061, valid error: 53.59556198120117\n",
      "Epoch [26/100], Training Loss: 49.2422\n",
      "Validation Loss: 51.9400, valid error: 52.330970764160156\n",
      "Epoch [27/100], Training Loss: 48.0317\n",
      "Validation Loss: 50.3168, valid error: 50.706417083740234\n",
      "Epoch [28/100], Training Loss: 46.6359\n",
      "Validation Loss: 49.7687, valid error: 50.16151809692383\n",
      "Epoch [29/100], Training Loss: 45.4968\n",
      "Validation Loss: 49.5882, valid error: 49.979557037353516\n",
      "Epoch [30/100], Training Loss: 44.7273\n",
      "Validation Loss: 48.4651, valid error: 48.85838317871094\n",
      "Epoch [31/100], Training Loss: 43.8303\n",
      "Validation Loss: 47.7449, valid error: 48.13304138183594\n",
      "Epoch [32/100], Training Loss: 43.0747\n",
      "Validation Loss: 48.2579, valid error: 48.64548873901367\n",
      "Epoch [33/100], Training Loss: 42.4888\n",
      "Validation Loss: 47.1761, valid error: 47.5655403137207\n",
      "Epoch [34/100], Training Loss: 41.9409\n",
      "Validation Loss: 46.3487, valid error: 46.7440185546875\n",
      "Epoch [35/100], Training Loss: 41.3761\n",
      "Validation Loss: 46.8070, valid error: 47.194252014160156\n",
      "Epoch [36/100], Training Loss: 40.9039\n",
      "Validation Loss: 46.0558, valid error: 46.44717025756836\n",
      "Epoch [37/100], Training Loss: 40.5274\n",
      "Validation Loss: 45.1123, valid error: 45.50259017944336\n",
      "Epoch [38/100], Training Loss: 40.0522\n",
      "Validation Loss: 45.6627, valid error: 46.050113677978516\n",
      "Epoch [39/100], Training Loss: 39.7056\n",
      "Validation Loss: 45.2491, valid error: 45.63821029663086\n",
      "Epoch [40/100], Training Loss: 39.3446\n",
      "Validation Loss: 44.8061, valid error: 45.19639587402344\n",
      "Epoch [41/100], Training Loss: 38.9119\n",
      "Validation Loss: 44.3817, valid error: 44.77396011352539\n",
      "Epoch [42/100], Training Loss: 38.7469\n",
      "Validation Loss: 44.0102, valid error: 44.399085998535156\n",
      "Epoch [43/100], Training Loss: 38.3814\n",
      "Validation Loss: 43.8666, valid error: 44.26070785522461\n",
      "Epoch [44/100], Training Loss: 38.0980\n",
      "Validation Loss: 43.6715, valid error: 44.06285095214844\n",
      "Epoch [45/100], Training Loss: 37.7478\n",
      "Validation Loss: 43.3938, valid error: 43.782501220703125\n",
      "Epoch [46/100], Training Loss: 37.5072\n",
      "Validation Loss: 44.0234, valid error: 44.41560745239258\n",
      "Epoch [47/100], Training Loss: 37.2765\n",
      "Validation Loss: 43.3666, valid error: 43.75948715209961\n",
      "Epoch [48/100], Training Loss: 37.1080\n",
      "Validation Loss: 43.2269, valid error: 43.61912155151367\n",
      "Epoch [49/100], Training Loss: 36.7477\n",
      "Validation Loss: 43.0974, valid error: 43.48727798461914\n",
      "Epoch [50/100], Training Loss: 36.5716\n",
      "Validation Loss: 43.3495, valid error: 43.74016189575195\n",
      "Epoch [51/100], Training Loss: 36.3533\n",
      "Validation Loss: 42.6307, valid error: 43.018821716308594\n",
      "Epoch [52/100], Training Loss: 36.1126\n",
      "Validation Loss: 42.2903, valid error: 42.67854309082031\n",
      "Epoch [53/100], Training Loss: 35.9713\n",
      "Validation Loss: 42.3271, valid error: 42.71992111206055\n",
      "Epoch [54/100], Training Loss: 35.7109\n",
      "Validation Loss: 42.2796, valid error: 42.66713333129883\n",
      "Epoch [55/100], Training Loss: 35.5580\n",
      "Validation Loss: 42.5276, valid error: 42.919429779052734\n",
      "Epoch [56/100], Training Loss: 35.3904\n",
      "Validation Loss: 41.9900, valid error: 42.379390716552734\n",
      "Epoch [57/100], Training Loss: 35.1646\n",
      "Validation Loss: 41.9235, valid error: 42.31068801879883\n",
      "Epoch [58/100], Training Loss: 34.9887\n",
      "Validation Loss: 42.3784, valid error: 42.76906204223633\n",
      "Epoch [59/100], Training Loss: 34.6364\n",
      "Validation Loss: 41.9315, valid error: 42.31877517700195\n",
      "Epoch [60/100], Training Loss: 34.5653\n",
      "Validation Loss: 41.8607, valid error: 42.249351501464844\n",
      "Epoch [61/100], Training Loss: 34.3472\n",
      "Validation Loss: 42.3146, valid error: 42.70307922363281\n",
      "Epoch [62/100], Training Loss: 34.2296\n",
      "Validation Loss: 41.8816, valid error: 42.271053314208984\n",
      "Epoch [63/100], Training Loss: 34.0340\n",
      "Validation Loss: 41.8561, valid error: 42.24518585205078\n",
      "Epoch [64/100], Training Loss: 33.8257\n",
      "Validation Loss: 41.7366, valid error: 42.12442398071289\n",
      "Epoch [65/100], Training Loss: 33.5090\n",
      "Validation Loss: 41.9765, valid error: 42.36579895019531\n",
      "Epoch [66/100], Training Loss: 33.4856\n",
      "Validation Loss: 41.4371, valid error: 41.82585525512695\n",
      "Epoch [67/100], Training Loss: 33.2628\n",
      "Validation Loss: 41.1905, valid error: 41.57974624633789\n",
      "Epoch [68/100], Training Loss: 33.2130\n",
      "Validation Loss: 41.1463, valid error: 41.53529739379883\n",
      "Epoch [69/100], Training Loss: 32.9436\n",
      "Validation Loss: 41.0337, valid error: 41.42741012573242\n",
      "Epoch [70/100], Training Loss: 32.8550\n",
      "Validation Loss: 41.2383, valid error: 41.62963104248047\n",
      "Epoch [71/100], Training Loss: 32.5959\n",
      "Validation Loss: 41.4693, valid error: 41.85736083984375\n",
      "Epoch [72/100], Training Loss: 32.5871\n",
      "Validation Loss: 40.9020, valid error: 41.289947509765625\n",
      "Epoch [73/100], Training Loss: 32.6256\n",
      "Validation Loss: 40.8845, valid error: 41.27177047729492\n",
      "Epoch [74/100], Training Loss: 32.4126\n",
      "Validation Loss: 41.1247, valid error: 41.5180549621582\n",
      "Epoch [75/100], Training Loss: 32.1486\n",
      "Validation Loss: 40.7493, valid error: 41.137786865234375\n",
      "Epoch [76/100], Training Loss: 32.0171\n",
      "Validation Loss: 41.0179, valid error: 41.409793853759766\n",
      "Epoch [77/100], Training Loss: 31.8922\n",
      "Validation Loss: 41.2900, valid error: 41.6781120300293\n",
      "Epoch [78/100], Training Loss: 31.7692\n",
      "Validation Loss: 41.3948, valid error: 41.78652572631836\n",
      "Epoch [79/100], Training Loss: 31.4915\n",
      "Validation Loss: 41.1289, valid error: 41.515960693359375\n",
      "Epoch [80/100], Training Loss: 31.4800\n",
      "Validation Loss: 40.4335, valid error: 40.82321548461914\n",
      "Epoch [81/100], Training Loss: 31.4477\n",
      "Validation Loss: 40.7431, valid error: 41.1307487487793\n",
      "Epoch [82/100], Training Loss: 31.2736\n",
      "Validation Loss: 40.5124, valid error: 40.899173736572266\n",
      "Epoch [83/100], Training Loss: 31.1272\n",
      "Validation Loss: 40.2871, valid error: 40.673828125\n",
      "Epoch [84/100], Training Loss: 30.9744\n",
      "Validation Loss: 40.1724, valid error: 40.560699462890625\n",
      "Epoch [85/100], Training Loss: 30.8332\n",
      "Validation Loss: 40.4754, valid error: 40.863853454589844\n",
      "Epoch [86/100], Training Loss: 30.7630\n",
      "Validation Loss: 40.3928, valid error: 40.78086853027344\n",
      "Epoch [87/100], Training Loss: 30.5803\n",
      "Validation Loss: 40.2909, valid error: 40.679744720458984\n",
      "Epoch [88/100], Training Loss: 30.5333\n",
      "Validation Loss: 40.4199, valid error: 40.80744934082031\n",
      "Epoch [89/100], Training Loss: 30.4465\n",
      "Validation Loss: 40.3041, valid error: 40.69450759887695\n",
      "Epoch [90/100], Training Loss: 30.3180\n",
      "Validation Loss: 40.3022, valid error: 40.689937591552734\n",
      "Epoch [91/100], Training Loss: 30.2564\n",
      "Validation Loss: 40.3046, valid error: 40.69450378417969\n",
      "Epoch [92/100], Training Loss: 30.1476\n",
      "Validation Loss: 40.5894, valid error: 40.97695541381836\n",
      "Epoch [93/100], Training Loss: 30.0333\n",
      "Validation Loss: 40.5778, valid error: 40.966495513916016\n",
      "Epoch [94/100], Training Loss: 29.9352\n",
      "Validation Loss: 40.1977, valid error: 40.58512496948242\n",
      "Epoch [95/100], Training Loss: 29.8330\n",
      "Validation Loss: 39.9256, valid error: 40.314022064208984\n",
      "Epoch [96/100], Training Loss: 29.6784\n",
      "Validation Loss: 39.9500, valid error: 40.33785629272461\n",
      "Epoch [97/100], Training Loss: 29.6343\n",
      "Validation Loss: 40.0055, valid error: 40.39389419555664\n",
      "Epoch [98/100], Training Loss: 29.5616\n",
      "Validation Loss: 39.9973, valid error: 40.38554000854492\n",
      "Epoch [99/100], Training Loss: 29.3537\n",
      "Validation Loss: 40.0054, valid error: 40.393009185791016\n",
      "Epoch [100/100], Training Loss: 29.3503\n",
      "Validation Loss: 39.9474, valid error: 40.33395004272461\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(256, 1, input_dim=5)\n",
    "train_model(model, train_loader, valid_loader, 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 10.5618, valid error: 10.676340103149414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17764.945638533998"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.SmoothL1Loss()\n",
    "model = model.to(device='cuda', dtype=torch.float32)\n",
    "validate_model(model, test_loader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: [127.87 168.04 178.48 131.88 127.86]\n",
      "label: [142.16 177.88 181.75 128.5  121.56]\n",
      "\n",
      "predict: [ 373.86 1293.41  496.41  838.75  400.77]\n",
      "label: [ 424.09 1474.43  389.77  820.32  444.58]\n",
      "\n",
      "predict: [328.08 440.36 400.33 388.55 433.53]\n",
      "label: [382.84 536.03 474.4  441.78 485.09]\n",
      "\n",
      "predict: [682.6  659.43 397.04 332.2  238.  ]\n",
      "label: [747.16 783.2  465.75 495.9  256.67]\n",
      "\n",
      "predict: [ 500.67  489.34  845.77 1431.45 1571.62]\n",
      "label: [ 489.74  453.32  851.91 1436.64 1556.22]\n",
      "\n",
      "predict: [ 4.21  7.97 12.56 16.41 30.52]\n",
      "label: [ 5.18  7.5  12.22 19.52 33.89]\n",
      "\n",
      "predict: [562.57 274.41 144.89 180.23 261.56]\n",
      "label: [225.71 118.12  61.42  76.44 117.26]\n",
      "\n",
      "predict: [127.85 106.12  68.44  56.56  52.83]\n",
      "label: [63.32 64.89 49.77 42.66 41.16]\n",
      "\n",
      "predict: [744.24 842.68 660.32 216.44 154.41]\n",
      "label: [1060.98 1114.58 1042.58  454.89  270.38]\n",
      "\n",
      "predict: [  3.36   8.21  80.62 108.57 165.69]\n",
      "label: [ 21.88  45.13  68.67 104.84 160.44]\n",
      "\n",
      "predict: [166.27 217.07 247.   168.6  133.94]\n",
      "label: [140.61 195.36 215.38 159.56 126.88]\n",
      "\n",
      "predict: [96.65 71.3  72.2  44.76 59.15]\n",
      "label: [101.34  62.7   61.97  48.29  65.38]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\weiso131\\AppData\\Local\\Temp\\ipykernel_17416\\3474920510.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  test_data_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_data]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict: [ 732.6  1038.06 1539.27 1401.15 1497.84]\n",
      "label: [ 754.64  986.15 1393.39 1267.34 1398.59]\n",
      "\n",
      "predict: [33.76 23.5  21.86 27.88 41.1 ]\n",
      "label: [23.21 16.48 16.57 22.79 36.8 ]\n",
      "\n",
      "predict: [ 5.6   7.76 15.26 44.37 83.13]\n",
      "label: [  7.34   9.92  15.84  55.38 103.91]\n",
      "\n",
      "predict: [ 86.03 104.16 100.5  151.6  166.76]\n",
      "label: [ 79.    99.32 107.57 164.04 161.65]\n",
      "\n",
      "predict: [809.92 961.13 880.73 807.45 792.16]\n",
      "label: [972.66 918.66 874.48 802.47 748.42]\n",
      "\n",
      "predict: [ 799.8   889.1   979.54 1224.5  1519.91]\n",
      "label: [1019.88 1146.97 1269.31 1388.88 1489.77]\n",
      "\n",
      "predict: [40.   36.25  6.18  8.45 58.7 ]\n",
      "label: [36.25 34.54  4.85  8.11 49.94]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device='cpu')\n",
    "test_data_tensors = [torch.tensor(seq, dtype=torch.float32) for seq in test_data]\n",
    "\n",
    "for x, y in valid_loader:\n",
    "\n",
    "    with torch.no_grad():\n",
    "        hidden = model.init_hidden(batch_size=x.size(0))\n",
    "        predict, _ = model(x, hidden)\n",
    "\n",
    "        predict_print = (torch.round(predict * 100) / 100).numpy()\n",
    "        #predict_print = label_normalizer.denormalize(predict_print)\n",
    "        y_print = (torch.round(y * 100) / 100).numpy()\n",
    "        np.set_printoptions(precision=2, suppress=True)\n",
    "        if max(y_print[0]) > 30:\n",
    "\n",
    "            print(\"predict:\", predict_print[0, :, 0])\n",
    "            print(\"label:\", y_print[0])\n",
    "            print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
