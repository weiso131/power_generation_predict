{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from utils.csv_to_pd import *\n",
    "from utils.lstm_tool import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>2024-03-01 17:14:06.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1017.48</td>\n",
       "      <td>15.59</td>\n",
       "      <td>94.3</td>\n",
       "      <td>652.92</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationCode                 DateTime  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0            10  2024-03-01 17:14:06.000             0.0        1017.48   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0            15.59         94.3         652.92       0.12  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_dir_csv()\n",
    "\n",
    "location_ori = list(df[\"LocationCode\"]) \n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00          10.0        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0        15.712857    93.771429     652.797143   0.115714  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = mean_min(df)\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>176.002661</td>\n",
       "      <td>0.124286</td>\n",
       "      <td>1017.49</td>\n",
       "      <td>15.712857</td>\n",
       "      <td>93.771429</td>\n",
       "      <td>652.797143</td>\n",
       "      <td>0.115714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00    176.002661        0.124286        1017.49   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0        15.712857    93.771429     652.797143   0.115714  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import category_encoders as ce\n",
    "\n",
    "encoder = ce.LeaveOneOutEncoder(cols=[\"LocationCode\"], sigma = 0.05)\n",
    "encoder.fit(df, df['Power(mW)'])\n",
    "df = encoder.transform(df)\n",
    "\n",
    "df[:1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>LocationCode</th>\n",
       "      <th>WindSpeed(m/s)</th>\n",
       "      <th>Pressure(hpa)</th>\n",
       "      <th>Temperature(°C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Sunlight(Lux)</th>\n",
       "      <th>Power(mW)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-03-01 17:10:00</td>\n",
       "      <td>-0.728083</td>\n",
       "      <td>-0.269455</td>\n",
       "      <td>0.780891</td>\n",
       "      <td>-1.672942</td>\n",
       "      <td>0.932812</td>\n",
       "      <td>-0.718723</td>\n",
       "      <td>0.115714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             DateTime  LocationCode  WindSpeed(m/s)  Pressure(hpa)  \\\n",
       "0 2024-03-01 17:10:00     -0.728083       -0.269455       0.780891   \n",
       "\n",
       "   Temperature(°C)  Humidity(%)  Sunlight(Lux)  Power(mW)  \n",
       "0        -1.672942     0.932812      -0.718723   0.115714  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 指定要標準化的欄位\n",
    "columns_to_standardize = ['WindSpeed(m/s)', 'Pressure(hpa)', 'Temperature(°C)', 'Humidity(%)', 'Sunlight(Lux)', \"LocationCode\"]\n",
    "\n",
    "# 初始化 StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# 對指定欄位進行標準化\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "\n",
    "df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 4])\n"
     ]
    }
   ],
   "source": [
    "data_label_list, _ = spilt_data_with_datetime(df, location_ori)\n",
    "\n",
    "print(data_label_list[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 torch.Size([85, 4]) torch.Size([85])\n",
      "1 torch.Size([1, 4]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_data_label_list, valid_data_label_list = split_data_random(data_label_list)\n",
    "\n",
    "train_data, train_label, train_length = sort_by_length(train_data_label_list)\n",
    "valid_data, valid_label, valid_length = sort_by_length(valid_data_label_list)\n",
    "\n",
    "print(train_data_label_list[0][0], train_data_label_list[0][1].shape, train_data_label_list[0][2].shape)\n",
    "print(train_length[0], train_data[0].shape, train_label[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_train_data, batch_train_label, batch_train_length = padding(train_data, train_label, train_length)\n",
    "batch_valid_data, batch_valid_label, batch_valid_length = padding(valid_data, valid_label, valid_length)\n",
    "\n",
    "batch_train_data[-1].shape\n",
    "\n",
    "train_loader = list(zip(batch_train_data, batch_train_label, batch_train_length))\n",
    "valid_loader = list(zip(batch_valid_data, batch_valid_label, batch_valid_length))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class LSTMTagger(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_dim, tagset_size, input_dim=6):\n",
    "        super(LSTMTagger, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # LSTM層\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, batch_first=True)\n",
    "\n",
    "        # 線性層\n",
    "        self.linear = nn.Linear(hidden_dim, tagset_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        # 初始化隱藏狀態和細胞狀態\n",
    "        return (torch.zeros(1, batch_size, self.hidden_dim),\n",
    "                torch.zeros(1, batch_size, self.hidden_dim))\n",
    "\n",
    "    def forward(self, sentence, hidden, lengths):\n",
    "        \"\"\"\n",
    "        sentence: Tensor, shape (batch_size, seq_len, input_dim)\n",
    "        lengths: List of sequence lengths (before padding)\n",
    "        hidden: Initial hidden state\n",
    "\n",
    "        Returns:\n",
    "            tag_space: Tensor, shape (batch_size, seq_len, tagset_size)\n",
    "            hidden: Final hidden state\n",
    "        \"\"\"\n",
    "        # 動態打包序列\n",
    "        packed_input = pack_padded_sequence(sentence, lengths, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # LSTM層\n",
    "        packed_output, hidden = self.lstm(packed_input, hidden)\n",
    "\n",
    "        # 解包序列\n",
    "        lstm_out, _ = pad_packed_sequence(packed_output, batch_first=True)\n",
    "        # lstm_out, hidden = self.lstm(sentence, hidden)\n",
    "        # 線性層和激活函數\n",
    "\n",
    "\n",
    "        tag_space = self.relu(self.linear(self.relu(lstm_out)))\n",
    "\n",
    "        return tag_space, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# 設置 GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 定義訓練函數\n",
    "def train_model(model, train_loader, valid_loader, train_length, valid_length, num_epochs=10, learning_rate=0.001):\n",
    "    # 將模型移到 GPU\n",
    "    model = model.to(device, dtype=torch.float32)\n",
    "    # 使用 Adam 優化器\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # 定義損失函數\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for inputs, labels, length in train_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels, length = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32), length.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            \n",
    "\n",
    "            # 清零梯度\n",
    "            optimizer.zero_grad()\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden, length)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels)\n",
    "            # 反向傳播\n",
    "            loss.backward()\n",
    "            # 更新參數\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Training Loss: {total_loss / train_length:.4f}\")\n",
    "\n",
    "        # 驗證模型\n",
    "        validate_model(model, valid_loader, criterion, valid_length)\n",
    "\n",
    "# 定義驗證函數\n",
    "def validate_model(model, valid_loader, criterion, valid_length):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    error = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, length in valid_loader:\n",
    "            # 將輸入和標籤移到 GPU\n",
    "            inputs, labels, length = inputs.to(device, dtype=torch.float32), labels.to(device, dtype=torch.float32), length.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            # 初始化隱藏狀態\n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "\n",
    "            # 前向傳播\n",
    "            outputs, _ = model(inputs, hidden, length)\n",
    "            # 計算損失\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "            error += abs(outputs.view(-1) - labels.view(-1)).sum() / inputs.shape[0] / inputs.shape[1]\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    print(f\"Validation Loss: {total_loss / valid_length:.4f}, valid error: {error / valid_length}\")\n",
    "    return total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/600], Training Loss: 207.2473\n",
      "Validation Loss: 182.1239, valid error: 182.50051879882812\n",
      "Epoch [2/600], Training Loss: 205.7449\n",
      "Validation Loss: 181.2249, valid error: 181.59962463378906\n",
      "Epoch [3/600], Training Loss: 205.1334\n",
      "Validation Loss: 180.7548, valid error: 181.13775634765625\n",
      "Epoch [4/600], Training Loss: 204.5883\n",
      "Validation Loss: 180.2242, valid error: 180.60740661621094\n",
      "Epoch [5/600], Training Loss: 204.1217\n",
      "Validation Loss: 179.7604, valid error: 180.14781188964844\n",
      "Epoch [6/600], Training Loss: 203.0462\n",
      "Validation Loss: 178.0840, valid error: 178.4658203125\n",
      "Epoch [7/600], Training Loss: 200.5987\n",
      "Validation Loss: 175.6525, valid error: 176.03231811523438\n",
      "Epoch [8/600], Training Loss: 198.5935\n",
      "Validation Loss: 173.9623, valid error: 174.3509521484375\n",
      "Epoch [9/600], Training Loss: 196.9517\n",
      "Validation Loss: 172.5153, valid error: 172.9031982421875\n",
      "Epoch [10/600], Training Loss: 195.4114\n",
      "Validation Loss: 171.3992, valid error: 171.7957000732422\n",
      "Epoch [11/600], Training Loss: 193.8644\n",
      "Validation Loss: 170.3088, valid error: 170.698486328125\n",
      "Epoch [12/600], Training Loss: 192.5600\n",
      "Validation Loss: 169.1019, valid error: 169.4932861328125\n",
      "Epoch [13/600], Training Loss: 191.0708\n",
      "Validation Loss: 167.5152, valid error: 167.9102325439453\n",
      "Epoch [14/600], Training Loss: 189.7349\n",
      "Validation Loss: 166.3249, valid error: 166.72227478027344\n",
      "Epoch [15/600], Training Loss: 188.3307\n",
      "Validation Loss: 164.8711, valid error: 165.27459716796875\n",
      "Epoch [16/600], Training Loss: 187.0507\n",
      "Validation Loss: 165.3751, valid error: 165.81097412109375\n",
      "Epoch [17/600], Training Loss: 187.7348\n",
      "Validation Loss: 165.7736, valid error: 166.18997192382812\n",
      "Epoch [18/600], Training Loss: 186.9425\n",
      "Validation Loss: 162.7073, valid error: 163.1299285888672\n",
      "Epoch [19/600], Training Loss: 185.4554\n",
      "Validation Loss: 161.7371, valid error: 162.16065979003906\n",
      "Epoch [20/600], Training Loss: 184.1042\n",
      "Validation Loss: 160.4366, valid error: 160.85679626464844\n",
      "Epoch [21/600], Training Loss: 182.7517\n",
      "Validation Loss: 159.6693, valid error: 160.08799743652344\n",
      "Epoch [22/600], Training Loss: 181.7570\n",
      "Validation Loss: 158.6347, valid error: 159.0554962158203\n",
      "Epoch [23/600], Training Loss: 180.6585\n",
      "Validation Loss: 157.4360, valid error: 157.85482788085938\n",
      "Epoch [24/600], Training Loss: 179.4480\n",
      "Validation Loss: 156.6267, valid error: 157.04690551757812\n",
      "Epoch [25/600], Training Loss: 178.4587\n",
      "Validation Loss: 155.5608, valid error: 155.98008728027344\n",
      "Epoch [26/600], Training Loss: 177.2149\n",
      "Validation Loss: 154.7198, valid error: 155.13980102539062\n",
      "Epoch [27/600], Training Loss: 176.2476\n",
      "Validation Loss: 153.8433, valid error: 154.2632293701172\n",
      "Epoch [28/600], Training Loss: 175.2535\n",
      "Validation Loss: 152.9907, valid error: 153.4110107421875\n",
      "Epoch [29/600], Training Loss: 174.2239\n",
      "Validation Loss: 152.1587, valid error: 152.58114624023438\n",
      "Epoch [30/600], Training Loss: 173.2201\n",
      "Validation Loss: 151.2639, valid error: 151.68753051757812\n",
      "Epoch [31/600], Training Loss: 172.1458\n",
      "Validation Loss: 150.4351, valid error: 150.8599395751953\n",
      "Epoch [32/600], Training Loss: 171.1482\n",
      "Validation Loss: 149.5165, valid error: 149.9420166015625\n",
      "Epoch [33/600], Training Loss: 170.1672\n",
      "Validation Loss: 148.6084, valid error: 149.0349578857422\n",
      "Epoch [34/600], Training Loss: 169.1582\n",
      "Validation Loss: 147.7517, valid error: 148.17819213867188\n",
      "Epoch [35/600], Training Loss: 168.1909\n",
      "Validation Loss: 146.9073, valid error: 147.33424377441406\n",
      "Epoch [36/600], Training Loss: 167.2379\n",
      "Validation Loss: 146.1191, valid error: 146.54574584960938\n",
      "Epoch [37/600], Training Loss: 166.3169\n",
      "Validation Loss: 145.3464, valid error: 145.77389526367188\n",
      "Epoch [38/600], Training Loss: 165.4112\n",
      "Validation Loss: 144.6018, valid error: 145.02882385253906\n",
      "Epoch [39/600], Training Loss: 164.5351\n",
      "Validation Loss: 143.8503, valid error: 144.2773895263672\n",
      "Epoch [40/600], Training Loss: 163.6518\n",
      "Validation Loss: 143.0891, valid error: 143.51528930664062\n",
      "Epoch [41/600], Training Loss: 162.7653\n",
      "Validation Loss: 142.3650, valid error: 142.7899932861328\n",
      "Epoch [42/600], Training Loss: 161.8858\n",
      "Validation Loss: 141.6921, valid error: 142.11734008789062\n",
      "Epoch [43/600], Training Loss: 161.0677\n",
      "Validation Loss: 141.0769, valid error: 141.50338745117188\n",
      "Epoch [44/600], Training Loss: 160.2709\n",
      "Validation Loss: 140.3864, valid error: 140.8102569580078\n",
      "Epoch [45/600], Training Loss: 159.4283\n",
      "Validation Loss: 139.6976, valid error: 140.12164306640625\n",
      "Epoch [46/600], Training Loss: 158.6756\n",
      "Validation Loss: 138.9697, valid error: 139.39370727539062\n",
      "Epoch [47/600], Training Loss: 157.8162\n",
      "Validation Loss: 138.3067, valid error: 138.7343292236328\n",
      "Epoch [48/600], Training Loss: 157.0645\n",
      "Validation Loss: 137.6388, valid error: 138.06753540039062\n",
      "Epoch [49/600], Training Loss: 156.2075\n",
      "Validation Loss: 136.8640, valid error: 137.28912353515625\n",
      "Epoch [50/600], Training Loss: 155.3398\n",
      "Validation Loss: 136.2990, valid error: 136.7251434326172\n",
      "Epoch [51/600], Training Loss: 154.5764\n",
      "Validation Loss: 135.4890, valid error: 135.91281127929688\n",
      "Epoch [52/600], Training Loss: 153.6748\n",
      "Validation Loss: 134.9593, valid error: 135.38255310058594\n",
      "Epoch [53/600], Training Loss: 153.0218\n",
      "Validation Loss: 134.5409, valid error: 134.97140502929688\n",
      "Epoch [54/600], Training Loss: 152.2482\n",
      "Validation Loss: 133.7428, valid error: 134.1695098876953\n",
      "Epoch [55/600], Training Loss: 151.3636\n",
      "Validation Loss: 133.0923, valid error: 133.51800537109375\n",
      "Epoch [56/600], Training Loss: 150.6107\n",
      "Validation Loss: 132.4394, valid error: 132.8610076904297\n",
      "Epoch [57/600], Training Loss: 149.8091\n",
      "Validation Loss: 131.8117, valid error: 132.23204040527344\n",
      "Epoch [58/600], Training Loss: 149.0278\n",
      "Validation Loss: 131.1260, valid error: 131.54461669921875\n",
      "Epoch [59/600], Training Loss: 148.2543\n",
      "Validation Loss: 130.5852, valid error: 131.00357055664062\n",
      "Epoch [60/600], Training Loss: 147.5129\n",
      "Validation Loss: 129.9410, valid error: 130.35733032226562\n",
      "Epoch [61/600], Training Loss: 146.7461\n",
      "Validation Loss: 129.1897, valid error: 129.60789489746094\n",
      "Epoch [62/600], Training Loss: 145.9564\n",
      "Validation Loss: 128.5105, valid error: 128.92880249023438\n",
      "Epoch [63/600], Training Loss: 145.2316\n",
      "Validation Loss: 128.1005, valid error: 128.52182006835938\n",
      "Epoch [64/600], Training Loss: 144.5198\n",
      "Validation Loss: 127.3771, valid error: 127.79412841796875\n",
      "Epoch [65/600], Training Loss: 143.7886\n",
      "Validation Loss: 126.6579, valid error: 127.07614135742188\n",
      "Epoch [66/600], Training Loss: 142.9694\n",
      "Validation Loss: 126.1116, valid error: 126.53640747070312\n",
      "Epoch [67/600], Training Loss: 142.2398\n",
      "Validation Loss: 125.4304, valid error: 125.85260009765625\n",
      "Epoch [68/600], Training Loss: 141.5314\n",
      "Validation Loss: 124.7270, valid error: 125.15121459960938\n",
      "Epoch [69/600], Training Loss: 140.8107\n",
      "Validation Loss: 124.1028, valid error: 124.52763366699219\n",
      "Epoch [70/600], Training Loss: 140.0655\n",
      "Validation Loss: 123.7046, valid error: 124.13179779052734\n",
      "Epoch [71/600], Training Loss: 139.4216\n",
      "Validation Loss: 122.7987, valid error: 123.21871185302734\n",
      "Epoch [72/600], Training Loss: 138.6304\n",
      "Validation Loss: 122.1711, valid error: 122.5968017578125\n",
      "Epoch [73/600], Training Loss: 137.9452\n",
      "Validation Loss: 121.6256, valid error: 122.0469970703125\n",
      "Epoch [74/600], Training Loss: 137.3181\n",
      "Validation Loss: 120.8473, valid error: 121.26692199707031\n",
      "Epoch [75/600], Training Loss: 136.3608\n",
      "Validation Loss: 120.2149, valid error: 120.63624572753906\n",
      "Epoch [76/600], Training Loss: 135.7132\n",
      "Validation Loss: 119.7561, valid error: 120.17627716064453\n",
      "Epoch [77/600], Training Loss: 135.1326\n",
      "Validation Loss: 118.8062, valid error: 119.22787475585938\n",
      "Epoch [78/600], Training Loss: 134.2059\n",
      "Validation Loss: 118.1428, valid error: 118.56428527832031\n",
      "Epoch [79/600], Training Loss: 133.2972\n",
      "Validation Loss: 117.3151, valid error: 117.73950958251953\n",
      "Epoch [80/600], Training Loss: 132.6099\n",
      "Validation Loss: 116.7113, valid error: 117.13298034667969\n",
      "Epoch [81/600], Training Loss: 131.9114\n",
      "Validation Loss: 116.1183, valid error: 116.54228973388672\n",
      "Epoch [82/600], Training Loss: 131.0728\n",
      "Validation Loss: 115.4735, valid error: 115.89346313476562\n",
      "Epoch [83/600], Training Loss: 130.3915\n",
      "Validation Loss: 114.7498, valid error: 115.17853546142578\n",
      "Epoch [84/600], Training Loss: 129.6934\n",
      "Validation Loss: 114.2220, valid error: 114.64524841308594\n",
      "Epoch [85/600], Training Loss: 128.8910\n",
      "Validation Loss: 113.5700, valid error: 113.98663330078125\n",
      "Epoch [86/600], Training Loss: 128.1547\n",
      "Validation Loss: 112.5886, valid error: 113.00544738769531\n",
      "Epoch [87/600], Training Loss: 127.3998\n",
      "Validation Loss: 112.0732, valid error: 112.4913330078125\n",
      "Epoch [88/600], Training Loss: 126.6247\n",
      "Validation Loss: 111.3351, valid error: 111.76141357421875\n",
      "Epoch [89/600], Training Loss: 125.8112\n",
      "Validation Loss: 110.6677, valid error: 111.0906982421875\n",
      "Epoch [90/600], Training Loss: 125.1670\n",
      "Validation Loss: 109.9368, valid error: 110.35591125488281\n",
      "Epoch [91/600], Training Loss: 124.3935\n",
      "Validation Loss: 109.4669, valid error: 109.88963317871094\n",
      "Epoch [92/600], Training Loss: 123.6497\n",
      "Validation Loss: 108.8647, valid error: 109.28340148925781\n",
      "Epoch [93/600], Training Loss: 123.0225\n",
      "Validation Loss: 108.3545, valid error: 108.7752685546875\n",
      "Epoch [94/600], Training Loss: 122.3465\n",
      "Validation Loss: 107.5283, valid error: 107.9454574584961\n",
      "Epoch [95/600], Training Loss: 121.4589\n",
      "Validation Loss: 106.8655, valid error: 107.28185272216797\n",
      "Epoch [96/600], Training Loss: 120.6991\n",
      "Validation Loss: 106.2898, valid error: 106.71044158935547\n",
      "Epoch [97/600], Training Loss: 119.9964\n",
      "Validation Loss: 105.5311, valid error: 105.94500732421875\n",
      "Epoch [98/600], Training Loss: 119.3707\n",
      "Validation Loss: 105.0647, valid error: 105.48184967041016\n",
      "Epoch [99/600], Training Loss: 118.5317\n",
      "Validation Loss: 104.4417, valid error: 104.8614501953125\n",
      "Epoch [100/600], Training Loss: 117.7818\n",
      "Validation Loss: 103.7191, valid error: 104.13784790039062\n",
      "Epoch [101/600], Training Loss: 116.9814\n",
      "Validation Loss: 103.0746, valid error: 103.492919921875\n",
      "Epoch [102/600], Training Loss: 116.1873\n",
      "Validation Loss: 102.4053, valid error: 102.819091796875\n",
      "Epoch [103/600], Training Loss: 115.5245\n",
      "Validation Loss: 101.9081, valid error: 102.33150482177734\n",
      "Epoch [104/600], Training Loss: 114.8755\n",
      "Validation Loss: 101.4479, valid error: 101.86509704589844\n",
      "Epoch [105/600], Training Loss: 114.1304\n",
      "Validation Loss: 100.9044, valid error: 101.32405853271484\n",
      "Epoch [106/600], Training Loss: 113.4564\n",
      "Validation Loss: 100.3168, valid error: 100.74455261230469\n",
      "Epoch [107/600], Training Loss: 112.8019\n",
      "Validation Loss: 99.7924, valid error: 100.21762084960938\n",
      "Epoch [108/600], Training Loss: 112.1576\n",
      "Validation Loss: 99.2923, valid error: 99.72319793701172\n",
      "Epoch [109/600], Training Loss: 111.5470\n",
      "Validation Loss: 98.4440, valid error: 98.8700180053711\n",
      "Epoch [110/600], Training Loss: 111.1040\n",
      "Validation Loss: 98.1387, valid error: 98.56378173828125\n",
      "Epoch [111/600], Training Loss: 110.5564\n",
      "Validation Loss: 97.3456, valid error: 97.77131652832031\n",
      "Epoch [112/600], Training Loss: 109.7475\n",
      "Validation Loss: 96.5751, valid error: 97.00025177001953\n",
      "Epoch [113/600], Training Loss: 109.3476\n",
      "Validation Loss: 96.1798, valid error: 96.61039733886719\n",
      "Epoch [114/600], Training Loss: 108.4788\n",
      "Validation Loss: 95.5878, valid error: 96.01242065429688\n",
      "Epoch [115/600], Training Loss: 107.8488\n",
      "Validation Loss: 95.1642, valid error: 95.58488464355469\n",
      "Epoch [116/600], Training Loss: 107.1780\n",
      "Validation Loss: 94.5951, valid error: 95.01249694824219\n",
      "Epoch [117/600], Training Loss: 106.7653\n",
      "Validation Loss: 94.2185, valid error: 94.64209747314453\n",
      "Epoch [118/600], Training Loss: 106.3691\n",
      "Validation Loss: 93.4635, valid error: 93.88780975341797\n",
      "Epoch [119/600], Training Loss: 105.4117\n",
      "Validation Loss: 92.5290, valid error: 92.95209503173828\n",
      "Epoch [120/600], Training Loss: 104.6278\n",
      "Validation Loss: 91.8696, valid error: 92.28935241699219\n",
      "Epoch [121/600], Training Loss: 103.8255\n",
      "Validation Loss: 91.4285, valid error: 91.84942626953125\n",
      "Epoch [122/600], Training Loss: 103.2713\n",
      "Validation Loss: 90.7576, valid error: 91.17691040039062\n",
      "Epoch [123/600], Training Loss: 102.4342\n",
      "Validation Loss: 90.5509, valid error: 90.96917724609375\n",
      "Epoch [124/600], Training Loss: 101.8457\n",
      "Validation Loss: 89.8854, valid error: 90.30290985107422\n",
      "Epoch [125/600], Training Loss: 101.0516\n",
      "Validation Loss: 89.2092, valid error: 89.62659454345703\n",
      "Epoch [126/600], Training Loss: 100.3801\n",
      "Validation Loss: 88.7638, valid error: 89.18367004394531\n",
      "Epoch [127/600], Training Loss: 99.7394\n",
      "Validation Loss: 88.5587, valid error: 88.97942352294922\n",
      "Epoch [128/600], Training Loss: 99.1716\n",
      "Validation Loss: 87.5919, valid error: 88.01315307617188\n",
      "Epoch [129/600], Training Loss: 98.5521\n",
      "Validation Loss: 86.8731, valid error: 87.29681396484375\n",
      "Epoch [130/600], Training Loss: 98.0494\n",
      "Validation Loss: 87.0402, valid error: 87.46016693115234\n",
      "Epoch [131/600], Training Loss: 97.2484\n",
      "Validation Loss: 85.8415, valid error: 86.26481628417969\n",
      "Epoch [132/600], Training Loss: 96.5136\n",
      "Validation Loss: 85.3004, valid error: 85.71981048583984\n",
      "Epoch [133/600], Training Loss: 95.8214\n",
      "Validation Loss: 84.7692, valid error: 85.19546508789062\n",
      "Epoch [134/600], Training Loss: 95.2745\n",
      "Validation Loss: 84.3398, valid error: 84.76740264892578\n",
      "Epoch [135/600], Training Loss: 94.8340\n",
      "Validation Loss: 83.7523, valid error: 84.18356323242188\n",
      "Epoch [136/600], Training Loss: 94.0363\n",
      "Validation Loss: 82.9879, valid error: 83.41785430908203\n",
      "Epoch [137/600], Training Loss: 93.4008\n",
      "Validation Loss: 82.3248, valid error: 82.75222778320312\n",
      "Epoch [138/600], Training Loss: 92.8385\n",
      "Validation Loss: 82.2673, valid error: 82.69452667236328\n",
      "Epoch [139/600], Training Loss: 92.1401\n",
      "Validation Loss: 81.3918, valid error: 81.81591033935547\n",
      "Epoch [140/600], Training Loss: 91.6804\n",
      "Validation Loss: 80.8109, valid error: 81.2315673828125\n",
      "Epoch [141/600], Training Loss: 91.2863\n",
      "Validation Loss: 80.4772, valid error: 80.90106201171875\n",
      "Epoch [142/600], Training Loss: 90.4830\n",
      "Validation Loss: 79.8530, valid error: 80.2762451171875\n",
      "Epoch [143/600], Training Loss: 89.9600\n",
      "Validation Loss: 79.6695, valid error: 80.09211730957031\n",
      "Epoch [144/600], Training Loss: 89.6948\n",
      "Validation Loss: 79.0022, valid error: 79.4166488647461\n",
      "Epoch [145/600], Training Loss: 88.7907\n",
      "Validation Loss: 78.3586, valid error: 78.77577209472656\n",
      "Epoch [146/600], Training Loss: 88.0046\n",
      "Validation Loss: 78.2406, valid error: 78.6611557006836\n",
      "Epoch [147/600], Training Loss: 87.3857\n",
      "Validation Loss: 77.5363, valid error: 77.95581817626953\n",
      "Epoch [148/600], Training Loss: 86.8004\n",
      "Validation Loss: 76.9639, valid error: 77.383056640625\n",
      "Epoch [149/600], Training Loss: 86.3324\n",
      "Validation Loss: 76.3586, valid error: 76.77790069580078\n",
      "Epoch [150/600], Training Loss: 85.7497\n",
      "Validation Loss: 75.7254, valid error: 76.14193725585938\n",
      "Epoch [151/600], Training Loss: 85.5586\n",
      "Validation Loss: 75.6527, valid error: 76.0722885131836\n",
      "Epoch [152/600], Training Loss: 84.7780\n",
      "Validation Loss: 74.9407, valid error: 75.36105346679688\n",
      "Epoch [153/600], Training Loss: 84.1266\n",
      "Validation Loss: 74.7042, valid error: 75.12651062011719\n",
      "Epoch [154/600], Training Loss: 83.7972\n",
      "Validation Loss: 74.1272, valid error: 74.54938507080078\n",
      "Epoch [155/600], Training Loss: 83.1109\n",
      "Validation Loss: 74.1217, valid error: 74.54329681396484\n",
      "Epoch [156/600], Training Loss: 82.8647\n",
      "Validation Loss: 73.4056, valid error: 73.82717895507812\n",
      "Epoch [157/600], Training Loss: 82.4357\n",
      "Validation Loss: 73.3708, valid error: 73.79771423339844\n",
      "Epoch [158/600], Training Loss: 82.4532\n",
      "Validation Loss: 72.6253, valid error: 73.04664611816406\n",
      "Epoch [159/600], Training Loss: 81.8957\n",
      "Validation Loss: 71.8209, valid error: 72.23910522460938\n",
      "Epoch [160/600], Training Loss: 80.7285\n",
      "Validation Loss: 71.2733, valid error: 71.6903076171875\n",
      "Epoch [161/600], Training Loss: 80.1519\n",
      "Validation Loss: 70.9585, valid error: 71.3749771118164\n",
      "Epoch [162/600], Training Loss: 79.9390\n",
      "Validation Loss: 70.9718, valid error: 71.40967559814453\n",
      "Epoch [163/600], Training Loss: 79.3158\n",
      "Validation Loss: 70.3152, valid error: 70.74090576171875\n",
      "Epoch [164/600], Training Loss: 78.5122\n",
      "Validation Loss: 69.6381, valid error: 70.05839538574219\n",
      "Epoch [165/600], Training Loss: 77.8868\n",
      "Validation Loss: 69.3046, valid error: 69.72270202636719\n",
      "Epoch [166/600], Training Loss: 77.6136\n",
      "Validation Loss: 68.4565, valid error: 68.87748718261719\n",
      "Epoch [167/600], Training Loss: 77.1502\n",
      "Validation Loss: 68.2775, valid error: 68.70475769042969\n",
      "Epoch [168/600], Training Loss: 76.7627\n",
      "Validation Loss: 68.1932, valid error: 68.61369323730469\n",
      "Epoch [169/600], Training Loss: 76.3312\n",
      "Validation Loss: 68.0198, valid error: 68.45790100097656\n",
      "Epoch [170/600], Training Loss: 76.1038\n",
      "Validation Loss: 67.0811, valid error: 67.50895690917969\n",
      "Epoch [171/600], Training Loss: 75.4191\n",
      "Validation Loss: 66.6860, valid error: 67.10530853271484\n",
      "Epoch [172/600], Training Loss: 74.5734\n",
      "Validation Loss: 66.4677, valid error: 66.88731384277344\n",
      "Epoch [173/600], Training Loss: 74.4725\n",
      "Validation Loss: 65.6619, valid error: 66.08430480957031\n",
      "Epoch [174/600], Training Loss: 74.0146\n",
      "Validation Loss: 65.8294, valid error: 66.25619506835938\n",
      "Epoch [175/600], Training Loss: 73.3625\n",
      "Validation Loss: 64.8697, valid error: 65.2929458618164\n",
      "Epoch [176/600], Training Loss: 72.9122\n",
      "Validation Loss: 64.5201, valid error: 64.94879150390625\n",
      "Epoch [177/600], Training Loss: 72.3850\n",
      "Validation Loss: 64.3401, valid error: 64.77136993408203\n",
      "Epoch [178/600], Training Loss: 72.0165\n",
      "Validation Loss: 64.1175, valid error: 64.55026245117188\n",
      "Epoch [179/600], Training Loss: 71.2516\n",
      "Validation Loss: 63.8848, valid error: 64.32181549072266\n",
      "Epoch [180/600], Training Loss: 70.8700\n",
      "Validation Loss: 63.4908, valid error: 63.92707061767578\n",
      "Epoch [181/600], Training Loss: 70.7658\n",
      "Validation Loss: 63.2217, valid error: 63.658470153808594\n",
      "Epoch [182/600], Training Loss: 70.5174\n",
      "Validation Loss: 62.0104, valid error: 62.437889099121094\n",
      "Epoch [183/600], Training Loss: 71.0138\n",
      "Validation Loss: 61.9626, valid error: 62.38226318359375\n",
      "Epoch [184/600], Training Loss: 70.2137\n",
      "Validation Loss: 61.5343, valid error: 61.9498291015625\n",
      "Epoch [185/600], Training Loss: 69.3739\n",
      "Validation Loss: 61.1202, valid error: 61.5338020324707\n",
      "Epoch [186/600], Training Loss: 68.7265\n",
      "Validation Loss: 60.7569, valid error: 61.172950744628906\n",
      "Epoch [187/600], Training Loss: 68.6732\n",
      "Validation Loss: 60.7498, valid error: 61.16596984863281\n",
      "Epoch [188/600], Training Loss: 67.6162\n",
      "Validation Loss: 60.0726, valid error: 60.48779296875\n",
      "Epoch [189/600], Training Loss: 66.5588\n",
      "Validation Loss: 59.3219, valid error: 59.740478515625\n",
      "Epoch [190/600], Training Loss: 66.1243\n",
      "Validation Loss: 58.8514, valid error: 59.269020080566406\n",
      "Epoch [191/600], Training Loss: 65.4763\n",
      "Validation Loss: 58.3446, valid error: 58.76573944091797\n",
      "Epoch [192/600], Training Loss: 64.7202\n",
      "Validation Loss: 58.2080, valid error: 58.62660217285156\n",
      "Epoch [193/600], Training Loss: 64.2732\n",
      "Validation Loss: 57.9474, valid error: 58.373870849609375\n",
      "Epoch [194/600], Training Loss: 63.8883\n",
      "Validation Loss: 57.4847, valid error: 57.91576385498047\n",
      "Epoch [195/600], Training Loss: 63.2639\n",
      "Validation Loss: 57.1632, valid error: 57.58346176147461\n",
      "Epoch [196/600], Training Loss: 62.9444\n",
      "Validation Loss: 56.9439, valid error: 57.37122344970703\n",
      "Epoch [197/600], Training Loss: 62.4873\n",
      "Validation Loss: 56.6144, valid error: 57.042240142822266\n",
      "Epoch [198/600], Training Loss: 61.9205\n",
      "Validation Loss: 55.7395, valid error: 56.16371154785156\n",
      "Epoch [199/600], Training Loss: 61.7432\n",
      "Validation Loss: 55.7200, valid error: 56.15080261230469\n",
      "Epoch [200/600], Training Loss: 61.1276\n",
      "Validation Loss: 55.1278, valid error: 55.5567626953125\n",
      "Epoch [201/600], Training Loss: 60.5086\n",
      "Validation Loss: 55.0942, valid error: 55.51958465576172\n",
      "Epoch [202/600], Training Loss: 60.0456\n",
      "Validation Loss: 54.3847, valid error: 54.81920623779297\n",
      "Epoch [203/600], Training Loss: 59.5804\n",
      "Validation Loss: 54.7697, valid error: 55.20264434814453\n",
      "Epoch [204/600], Training Loss: 59.2490\n",
      "Validation Loss: 55.0591, valid error: 55.49030303955078\n",
      "Epoch [205/600], Training Loss: 59.0986\n",
      "Validation Loss: 53.1622, valid error: 53.58403015136719\n",
      "Epoch [206/600], Training Loss: 58.5489\n",
      "Validation Loss: 53.0041, valid error: 53.422550201416016\n",
      "Epoch [207/600], Training Loss: 57.9801\n",
      "Validation Loss: 53.3117, valid error: 53.72969055175781\n",
      "Epoch [208/600], Training Loss: 57.7241\n",
      "Validation Loss: 51.9392, valid error: 52.35383605957031\n",
      "Epoch [209/600], Training Loss: 57.3964\n",
      "Validation Loss: 52.2109, valid error: 52.626888275146484\n",
      "Epoch [210/600], Training Loss: 56.6167\n",
      "Validation Loss: 51.3378, valid error: 51.75852966308594\n",
      "Epoch [211/600], Training Loss: 55.9766\n",
      "Validation Loss: 51.4495, valid error: 51.87586975097656\n",
      "Epoch [212/600], Training Loss: 55.6004\n",
      "Validation Loss: 50.8580, valid error: 51.27878189086914\n",
      "Epoch [213/600], Training Loss: 55.2674\n",
      "Validation Loss: 50.5438, valid error: 50.97504425048828\n",
      "Epoch [214/600], Training Loss: 54.8638\n",
      "Validation Loss: 50.0837, valid error: 50.51988220214844\n",
      "Epoch [215/600], Training Loss: 54.9091\n",
      "Validation Loss: 50.2866, valid error: 50.71514892578125\n",
      "Epoch [216/600], Training Loss: 54.1302\n",
      "Validation Loss: 49.4705, valid error: 49.89410400390625\n",
      "Epoch [217/600], Training Loss: 53.6660\n",
      "Validation Loss: 49.1815, valid error: 49.615501403808594\n",
      "Epoch [218/600], Training Loss: 53.4269\n",
      "Validation Loss: 49.4545, valid error: 49.88569641113281\n",
      "Epoch [219/600], Training Loss: 52.9569\n",
      "Validation Loss: 49.4285, valid error: 49.862396240234375\n",
      "Epoch [220/600], Training Loss: 52.4551\n",
      "Validation Loss: 48.3036, valid error: 48.73705291748047\n",
      "Epoch [221/600], Training Loss: 51.7981\n",
      "Validation Loss: 48.2171, valid error: 48.64129638671875\n",
      "Epoch [222/600], Training Loss: 51.4941\n",
      "Validation Loss: 47.7626, valid error: 48.19273376464844\n",
      "Epoch [223/600], Training Loss: 51.0484\n",
      "Validation Loss: 47.5194, valid error: 47.947792053222656\n",
      "Epoch [224/600], Training Loss: 50.7421\n",
      "Validation Loss: 46.8969, valid error: 47.31754684448242\n",
      "Epoch [225/600], Training Loss: 50.4358\n",
      "Validation Loss: 46.5698, valid error: 46.98748016357422\n",
      "Epoch [226/600], Training Loss: 50.1012\n",
      "Validation Loss: 46.2888, valid error: 46.70800018310547\n",
      "Epoch [227/600], Training Loss: 49.8895\n",
      "Validation Loss: 45.7419, valid error: 46.16710662841797\n",
      "Epoch [228/600], Training Loss: 49.7555\n",
      "Validation Loss: 45.4892, valid error: 45.910179138183594\n",
      "Epoch [229/600], Training Loss: 49.0886\n",
      "Validation Loss: 45.0192, valid error: 45.43256759643555\n",
      "Epoch [230/600], Training Loss: 48.3349\n",
      "Validation Loss: 44.7473, valid error: 45.16202926635742\n",
      "Epoch [231/600], Training Loss: 47.7655\n",
      "Validation Loss: 44.9608, valid error: 45.37978744506836\n",
      "Epoch [232/600], Training Loss: 47.5327\n",
      "Validation Loss: 44.5204, valid error: 44.941314697265625\n",
      "Epoch [233/600], Training Loss: 47.0447\n",
      "Validation Loss: 43.9233, valid error: 44.345279693603516\n",
      "Epoch [234/600], Training Loss: 46.8769\n",
      "Validation Loss: 43.9990, valid error: 44.41531753540039\n",
      "Epoch [235/600], Training Loss: 46.1944\n",
      "Validation Loss: 43.9632, valid error: 44.37984085083008\n",
      "Epoch [236/600], Training Loss: 46.3996\n",
      "Validation Loss: 44.0872, valid error: 44.50321578979492\n",
      "Epoch [237/600], Training Loss: 46.0459\n",
      "Validation Loss: 44.0782, valid error: 44.497562408447266\n",
      "Epoch [238/600], Training Loss: 45.7128\n",
      "Validation Loss: 43.3088, valid error: 43.7303466796875\n",
      "Epoch [239/600], Training Loss: 46.6233\n",
      "Validation Loss: 43.2696, valid error: 43.68759536743164\n",
      "Epoch [240/600], Training Loss: 46.3596\n",
      "Validation Loss: 42.8920, valid error: 43.307525634765625\n",
      "Epoch [241/600], Training Loss: 46.4432\n",
      "Validation Loss: 43.0227, valid error: 43.442779541015625\n",
      "Epoch [242/600], Training Loss: 46.4580\n",
      "Validation Loss: 43.0548, valid error: 43.47502517700195\n",
      "Epoch [243/600], Training Loss: 45.6964\n",
      "Validation Loss: 43.4270, valid error: 43.85300064086914\n",
      "Epoch [244/600], Training Loss: 44.7594\n",
      "Validation Loss: 42.0811, valid error: 42.4984130859375\n",
      "Epoch [245/600], Training Loss: 44.0337\n",
      "Validation Loss: 41.9792, valid error: 42.40883255004883\n",
      "Epoch [246/600], Training Loss: 43.3503\n",
      "Validation Loss: 41.7806, valid error: 42.20466995239258\n",
      "Epoch [247/600], Training Loss: 42.3527\n",
      "Validation Loss: 41.5393, valid error: 41.95958709716797\n",
      "Epoch [248/600], Training Loss: 41.8619\n",
      "Validation Loss: 41.4293, valid error: 41.844871520996094\n",
      "Epoch [249/600], Training Loss: 41.4694\n",
      "Validation Loss: 40.2561, valid error: 40.67793655395508\n",
      "Epoch [250/600], Training Loss: 41.3466\n",
      "Validation Loss: 40.3321, valid error: 40.751583099365234\n",
      "Epoch [251/600], Training Loss: 40.9386\n",
      "Validation Loss: 40.1078, valid error: 40.53239440917969\n",
      "Epoch [252/600], Training Loss: 40.7562\n",
      "Validation Loss: 39.7072, valid error: 40.129432678222656\n",
      "Epoch [253/600], Training Loss: 40.2073\n",
      "Validation Loss: 39.7968, valid error: 40.222660064697266\n",
      "Epoch [254/600], Training Loss: 39.6621\n",
      "Validation Loss: 39.6618, valid error: 40.08438491821289\n",
      "Epoch [255/600], Training Loss: 39.7186\n",
      "Validation Loss: 39.7955, valid error: 40.22301483154297\n",
      "Epoch [256/600], Training Loss: 39.6435\n",
      "Validation Loss: 39.5506, valid error: 39.97254180908203\n",
      "Epoch [257/600], Training Loss: 39.6179\n",
      "Validation Loss: 39.9477, valid error: 40.36989212036133\n",
      "Epoch [258/600], Training Loss: 39.4788\n",
      "Validation Loss: 40.4996, valid error: 40.923057556152344\n",
      "Epoch [259/600], Training Loss: 39.0048\n",
      "Validation Loss: 41.1266, valid error: 41.56342315673828\n",
      "Epoch [260/600], Training Loss: 39.0673\n",
      "Validation Loss: 39.7773, valid error: 40.19855499267578\n",
      "Epoch [261/600], Training Loss: 39.7846\n",
      "Validation Loss: 39.2925, valid error: 39.72107696533203\n",
      "Epoch [262/600], Training Loss: 40.7176\n",
      "Validation Loss: 38.2247, valid error: 38.64326095581055\n",
      "Epoch [263/600], Training Loss: 40.7643\n",
      "Validation Loss: 38.7990, valid error: 39.21607208251953\n",
      "Epoch [264/600], Training Loss: 38.2846\n",
      "Validation Loss: 37.9919, valid error: 38.416847229003906\n",
      "Epoch [265/600], Training Loss: 36.8873\n",
      "Validation Loss: 37.3197, valid error: 37.74860382080078\n",
      "Epoch [266/600], Training Loss: 36.1774\n",
      "Validation Loss: 37.4781, valid error: 37.8974609375\n",
      "Epoch [267/600], Training Loss: 35.6344\n",
      "Validation Loss: 37.2204, valid error: 37.638671875\n",
      "Epoch [268/600], Training Loss: 35.3246\n",
      "Validation Loss: 36.5738, valid error: 36.99251937866211\n",
      "Epoch [269/600], Training Loss: 35.4652\n",
      "Validation Loss: 37.6634, valid error: 38.07837677001953\n",
      "Epoch [270/600], Training Loss: 35.1145\n",
      "Validation Loss: 36.5112, valid error: 36.92832565307617\n",
      "Epoch [271/600], Training Loss: 35.4645\n",
      "Validation Loss: 36.4870, valid error: 36.903900146484375\n",
      "Epoch [272/600], Training Loss: 35.5174\n",
      "Validation Loss: 37.0411, valid error: 37.462745666503906\n",
      "Epoch [273/600], Training Loss: 35.1618\n",
      "Validation Loss: 35.5694, valid error: 35.99085998535156\n",
      "Epoch [274/600], Training Loss: 34.7936\n",
      "Validation Loss: 36.4102, valid error: 36.830604553222656\n",
      "Epoch [275/600], Training Loss: 34.6527\n",
      "Validation Loss: 35.5144, valid error: 35.93449783325195\n",
      "Epoch [276/600], Training Loss: 34.3379\n",
      "Validation Loss: 35.8577, valid error: 36.27781677246094\n",
      "Epoch [277/600], Training Loss: 34.4069\n",
      "Validation Loss: 35.8580, valid error: 36.277565002441406\n",
      "Epoch [278/600], Training Loss: 34.5446\n",
      "Validation Loss: 36.3122, valid error: 36.73468780517578\n",
      "Epoch [279/600], Training Loss: 34.0715\n",
      "Validation Loss: 36.4354, valid error: 36.85149002075195\n",
      "Epoch [280/600], Training Loss: 33.4951\n",
      "Validation Loss: 34.9374, valid error: 35.35664749145508\n",
      "Epoch [281/600], Training Loss: 33.3322\n",
      "Validation Loss: 34.8408, valid error: 35.260013580322266\n",
      "Epoch [282/600], Training Loss: 33.3599\n",
      "Validation Loss: 35.4589, valid error: 35.88211441040039\n",
      "Epoch [283/600], Training Loss: 32.4943\n",
      "Validation Loss: 34.5752, valid error: 34.99265670776367\n",
      "Epoch [284/600], Training Loss: 31.9075\n",
      "Validation Loss: 34.8327, valid error: 35.25238037109375\n",
      "Epoch [285/600], Training Loss: 31.7111\n",
      "Validation Loss: 34.7219, valid error: 35.1418571472168\n",
      "Epoch [286/600], Training Loss: 31.5542\n",
      "Validation Loss: 34.7966, valid error: 35.21364212036133\n",
      "Epoch [287/600], Training Loss: 30.7908\n",
      "Validation Loss: 33.9404, valid error: 34.35520553588867\n",
      "Epoch [288/600], Training Loss: 30.7911\n",
      "Validation Loss: 33.9237, valid error: 34.33974838256836\n",
      "Epoch [289/600], Training Loss: 30.5584\n",
      "Validation Loss: 32.9715, valid error: 33.392189025878906\n",
      "Epoch [290/600], Training Loss: 31.3013\n",
      "Validation Loss: 33.0785, valid error: 33.500526428222656\n",
      "Epoch [291/600], Training Loss: 30.5829\n",
      "Validation Loss: 33.7082, valid error: 34.122737884521484\n",
      "Epoch [292/600], Training Loss: 30.1255\n",
      "Validation Loss: 33.6827, valid error: 34.099037170410156\n",
      "Epoch [293/600], Training Loss: 29.5755\n",
      "Validation Loss: 33.5480, valid error: 33.96624755859375\n",
      "Epoch [294/600], Training Loss: 29.5191\n",
      "Validation Loss: 33.8193, valid error: 34.23419189453125\n",
      "Epoch [295/600], Training Loss: 29.3938\n",
      "Validation Loss: 33.8784, valid error: 34.300235748291016\n",
      "Epoch [296/600], Training Loss: 29.9205\n",
      "Validation Loss: 33.5980, valid error: 34.01492691040039\n",
      "Epoch [297/600], Training Loss: 29.3748\n",
      "Validation Loss: 32.8230, valid error: 33.238807678222656\n",
      "Epoch [298/600], Training Loss: 29.2441\n",
      "Validation Loss: 33.1303, valid error: 33.55091857910156\n",
      "Epoch [299/600], Training Loss: 29.0660\n",
      "Validation Loss: 33.3557, valid error: 33.777183532714844\n",
      "Epoch [300/600], Training Loss: 28.3854\n",
      "Validation Loss: 33.8514, valid error: 34.27289581298828\n",
      "Epoch [301/600], Training Loss: 28.3669\n",
      "Validation Loss: 33.9999, valid error: 34.416446685791016\n",
      "Epoch [302/600], Training Loss: 28.1234\n",
      "Validation Loss: 32.9366, valid error: 33.35830307006836\n",
      "Epoch [303/600], Training Loss: 28.0745\n",
      "Validation Loss: 32.6945, valid error: 33.11015319824219\n",
      "Epoch [304/600], Training Loss: 28.0527\n",
      "Validation Loss: 32.5382, valid error: 32.956321716308594\n",
      "Epoch [305/600], Training Loss: 27.3637\n",
      "Validation Loss: 33.2187, valid error: 33.634796142578125\n",
      "Epoch [306/600], Training Loss: 27.4470\n",
      "Validation Loss: 34.0377, valid error: 34.4554443359375\n",
      "Epoch [307/600], Training Loss: 27.2846\n",
      "Validation Loss: 34.3963, valid error: 34.81425857543945\n",
      "Epoch [308/600], Training Loss: 26.8483\n",
      "Validation Loss: 33.4423, valid error: 33.86145782470703\n",
      "Epoch [309/600], Training Loss: 27.0366\n",
      "Validation Loss: 33.0659, valid error: 33.48398208618164\n",
      "Epoch [310/600], Training Loss: 26.9263\n",
      "Validation Loss: 33.3746, valid error: 33.794212341308594\n",
      "Epoch [311/600], Training Loss: 26.5949\n",
      "Validation Loss: 32.8004, valid error: 33.21537780761719\n",
      "Epoch [312/600], Training Loss: 26.6218\n",
      "Validation Loss: 33.4957, valid error: 33.9146614074707\n",
      "Epoch [313/600], Training Loss: 26.2392\n",
      "Validation Loss: 35.8909, valid error: 36.30958557128906\n",
      "Epoch [314/600], Training Loss: 26.4166\n",
      "Validation Loss: 34.2682, valid error: 34.68299102783203\n",
      "Epoch [315/600], Training Loss: 26.1186\n",
      "Validation Loss: 32.6888, valid error: 33.108741760253906\n",
      "Epoch [316/600], Training Loss: 25.8462\n",
      "Validation Loss: 34.0500, valid error: 34.46504592895508\n",
      "Epoch [317/600], Training Loss: 25.3815\n",
      "Validation Loss: 34.2524, valid error: 34.67040252685547\n",
      "Epoch [318/600], Training Loss: 24.8826\n",
      "Validation Loss: 35.6611, valid error: 36.078330993652344\n",
      "Epoch [319/600], Training Loss: 25.1703\n",
      "Validation Loss: 34.4570, valid error: 34.8732795715332\n",
      "Epoch [320/600], Training Loss: 25.5184\n",
      "Validation Loss: 33.7925, valid error: 34.20923614501953\n",
      "Epoch [321/600], Training Loss: 25.4359\n",
      "Validation Loss: 33.5515, valid error: 33.969970703125\n",
      "Epoch [322/600], Training Loss: 25.5723\n",
      "Validation Loss: 34.4536, valid error: 34.86901092529297\n",
      "Epoch [323/600], Training Loss: 25.1095\n",
      "Validation Loss: 32.7964, valid error: 33.21756362915039\n",
      "Epoch [324/600], Training Loss: 27.3704\n",
      "Validation Loss: 32.3812, valid error: 32.80648422241211\n",
      "Epoch [325/600], Training Loss: 25.7764\n",
      "Validation Loss: 32.8491, valid error: 33.26956558227539\n",
      "Epoch [326/600], Training Loss: 25.8084\n",
      "Validation Loss: 31.0302, valid error: 31.457744598388672\n",
      "Epoch [327/600], Training Loss: 24.7278\n",
      "Validation Loss: 30.9573, valid error: 31.384031295776367\n",
      "Epoch [328/600], Training Loss: 24.0739\n",
      "Validation Loss: 32.2806, valid error: 32.705562591552734\n",
      "Epoch [329/600], Training Loss: 23.9562\n",
      "Validation Loss: 30.0837, valid error: 30.510663986206055\n",
      "Epoch [330/600], Training Loss: 23.6299\n",
      "Validation Loss: 29.6014, valid error: 30.01929473876953\n",
      "Epoch [331/600], Training Loss: 23.1949\n",
      "Validation Loss: 29.0060, valid error: 29.426918029785156\n",
      "Epoch [332/600], Training Loss: 22.9690\n",
      "Validation Loss: 28.8978, valid error: 29.314434051513672\n",
      "Epoch [333/600], Training Loss: 23.1778\n",
      "Validation Loss: 28.1256, valid error: 28.541278839111328\n",
      "Epoch [334/600], Training Loss: 23.3460\n",
      "Validation Loss: 28.0561, valid error: 28.472686767578125\n",
      "Epoch [335/600], Training Loss: 23.2388\n",
      "Validation Loss: 26.6956, valid error: 27.111595153808594\n",
      "Epoch [336/600], Training Loss: 22.3704\n",
      "Validation Loss: 25.9609, valid error: 26.377788543701172\n",
      "Epoch [337/600], Training Loss: 22.2377\n",
      "Validation Loss: 26.8159, valid error: 27.233680725097656\n",
      "Epoch [338/600], Training Loss: 22.1140\n",
      "Validation Loss: 27.5673, valid error: 27.990631103515625\n",
      "Epoch [339/600], Training Loss: 22.0058\n",
      "Validation Loss: 26.7713, valid error: 27.192398071289062\n",
      "Epoch [340/600], Training Loss: 21.8093\n",
      "Validation Loss: 27.3240, valid error: 27.743061065673828\n",
      "Epoch [341/600], Training Loss: 21.7253\n",
      "Validation Loss: 27.0293, valid error: 27.44943618774414\n",
      "Epoch [342/600], Training Loss: 21.8776\n",
      "Validation Loss: 26.8884, valid error: 27.309856414794922\n",
      "Epoch [343/600], Training Loss: 21.5081\n",
      "Validation Loss: 27.9534, valid error: 28.376358032226562\n",
      "Epoch [344/600], Training Loss: 21.6019\n",
      "Validation Loss: 27.8747, valid error: 28.297283172607422\n",
      "Epoch [345/600], Training Loss: 21.5709\n",
      "Validation Loss: 27.4168, valid error: 27.83770751953125\n",
      "Epoch [346/600], Training Loss: 21.6120\n",
      "Validation Loss: 26.1110, valid error: 26.531753540039062\n",
      "Epoch [347/600], Training Loss: 21.3421\n",
      "Validation Loss: 26.9608, valid error: 27.377849578857422\n",
      "Epoch [348/600], Training Loss: 20.7540\n",
      "Validation Loss: 25.6847, valid error: 26.100990295410156\n",
      "Epoch [349/600], Training Loss: 20.4691\n",
      "Validation Loss: 25.3469, valid error: 25.763938903808594\n",
      "Epoch [350/600], Training Loss: 20.2749\n",
      "Validation Loss: 24.4890, valid error: 24.90570068359375\n",
      "Epoch [351/600], Training Loss: 20.3794\n",
      "Validation Loss: 24.3458, valid error: 24.760150909423828\n",
      "Epoch [352/600], Training Loss: 20.2429\n",
      "Validation Loss: 24.3880, valid error: 24.80641746520996\n",
      "Epoch [353/600], Training Loss: 19.9816\n",
      "Validation Loss: 24.3205, valid error: 24.736133575439453\n",
      "Epoch [354/600], Training Loss: 19.6471\n",
      "Validation Loss: 24.6193, valid error: 25.035329818725586\n",
      "Epoch [355/600], Training Loss: 19.4251\n",
      "Validation Loss: 25.5351, valid error: 25.950397491455078\n",
      "Epoch [356/600], Training Loss: 19.2006\n",
      "Validation Loss: 25.5143, valid error: 25.929447174072266\n",
      "Epoch [357/600], Training Loss: 19.0396\n",
      "Validation Loss: 24.9923, valid error: 25.409957885742188\n",
      "Epoch [358/600], Training Loss: 19.0693\n",
      "Validation Loss: 25.3071, valid error: 25.72669219970703\n",
      "Epoch [359/600], Training Loss: 19.0458\n",
      "Validation Loss: 26.8325, valid error: 27.249252319335938\n",
      "Epoch [360/600], Training Loss: 19.0609\n",
      "Validation Loss: 28.1639, valid error: 28.58087158203125\n",
      "Epoch [361/600], Training Loss: 18.8681\n",
      "Validation Loss: 27.0111, valid error: 27.426654815673828\n",
      "Epoch [362/600], Training Loss: 18.6011\n",
      "Validation Loss: 25.6268, valid error: 26.040489196777344\n",
      "Epoch [363/600], Training Loss: 18.3220\n",
      "Validation Loss: 26.5154, valid error: 26.932628631591797\n",
      "Epoch [364/600], Training Loss: 18.5503\n",
      "Validation Loss: 26.4585, valid error: 26.872652053833008\n",
      "Epoch [365/600], Training Loss: 18.5297\n",
      "Validation Loss: 27.8270, valid error: 28.244091033935547\n",
      "Epoch [366/600], Training Loss: 19.0604\n",
      "Validation Loss: 28.2773, valid error: 28.698137283325195\n",
      "Epoch [367/600], Training Loss: 18.8435\n",
      "Validation Loss: 29.1462, valid error: 29.56542205810547\n",
      "Epoch [368/600], Training Loss: 18.8304\n",
      "Validation Loss: 26.5135, valid error: 26.929420471191406\n",
      "Epoch [369/600], Training Loss: 18.5496\n",
      "Validation Loss: 26.5266, valid error: 26.94278335571289\n",
      "Epoch [370/600], Training Loss: 18.2305\n",
      "Validation Loss: 25.0931, valid error: 25.504762649536133\n",
      "Epoch [371/600], Training Loss: 17.9633\n",
      "Validation Loss: 25.5542, valid error: 25.968355178833008\n",
      "Epoch [372/600], Training Loss: 18.0056\n",
      "Validation Loss: 24.9036, valid error: 25.31924057006836\n",
      "Epoch [373/600], Training Loss: 18.3816\n",
      "Validation Loss: 25.0601, valid error: 25.477645874023438\n",
      "Epoch [374/600], Training Loss: 18.5219\n",
      "Validation Loss: 23.0166, valid error: 23.436508178710938\n",
      "Epoch [375/600], Training Loss: 18.6747\n",
      "Validation Loss: 23.6191, valid error: 24.03498649597168\n",
      "Epoch [376/600], Training Loss: 18.3229\n",
      "Validation Loss: 22.8599, valid error: 23.27992820739746\n",
      "Epoch [377/600], Training Loss: 17.9973\n",
      "Validation Loss: 25.5936, valid error: 26.010366439819336\n",
      "Epoch [378/600], Training Loss: 17.8955\n",
      "Validation Loss: 23.6756, valid error: 24.093936920166016\n",
      "Epoch [379/600], Training Loss: 17.8987\n",
      "Validation Loss: 24.2498, valid error: 24.669700622558594\n",
      "Epoch [380/600], Training Loss: 17.6341\n",
      "Validation Loss: 24.1192, valid error: 24.542781829833984\n",
      "Epoch [381/600], Training Loss: 17.9215\n",
      "Validation Loss: 23.5234, valid error: 23.945423126220703\n",
      "Epoch [382/600], Training Loss: 17.5148\n",
      "Validation Loss: 23.2985, valid error: 23.717620849609375\n",
      "Epoch [383/600], Training Loss: 17.6792\n",
      "Validation Loss: 24.1432, valid error: 24.56193733215332\n",
      "Epoch [384/600], Training Loss: 17.6703\n",
      "Validation Loss: 23.3985, valid error: 23.816116333007812\n",
      "Epoch [385/600], Training Loss: 17.2933\n",
      "Validation Loss: 22.8191, valid error: 23.238182067871094\n",
      "Epoch [386/600], Training Loss: 17.1085\n",
      "Validation Loss: 22.2063, valid error: 22.62761878967285\n",
      "Epoch [387/600], Training Loss: 16.7318\n",
      "Validation Loss: 22.3590, valid error: 22.777511596679688\n",
      "Epoch [388/600], Training Loss: 16.5632\n",
      "Validation Loss: 21.9337, valid error: 22.353025436401367\n",
      "Epoch [389/600], Training Loss: 16.2016\n",
      "Validation Loss: 22.0413, valid error: 22.46040153503418\n",
      "Epoch [390/600], Training Loss: 16.3017\n",
      "Validation Loss: 22.0644, valid error: 22.48239517211914\n",
      "Epoch [391/600], Training Loss: 15.8467\n",
      "Validation Loss: 22.4437, valid error: 22.8587703704834\n",
      "Epoch [392/600], Training Loss: 15.8111\n",
      "Validation Loss: 22.4425, valid error: 22.85905647277832\n",
      "Epoch [393/600], Training Loss: 15.7036\n",
      "Validation Loss: 22.8238, valid error: 23.240230560302734\n",
      "Epoch [394/600], Training Loss: 15.8150\n",
      "Validation Loss: 23.2109, valid error: 23.62725830078125\n",
      "Epoch [395/600], Training Loss: 16.4171\n",
      "Validation Loss: 22.7417, valid error: 23.157550811767578\n",
      "Epoch [396/600], Training Loss: 16.4404\n",
      "Validation Loss: 22.8298, valid error: 23.24937629699707\n",
      "Epoch [397/600], Training Loss: 16.8434\n",
      "Validation Loss: 25.8060, valid error: 26.227367401123047\n",
      "Epoch [398/600], Training Loss: 16.4515\n",
      "Validation Loss: 25.9531, valid error: 26.369712829589844\n",
      "Epoch [399/600], Training Loss: 16.2608\n",
      "Validation Loss: 24.5632, valid error: 24.976900100708008\n",
      "Epoch [400/600], Training Loss: 16.4708\n",
      "Validation Loss: 23.6976, valid error: 24.113483428955078\n",
      "Epoch [401/600], Training Loss: 16.0970\n",
      "Validation Loss: 24.0517, valid error: 24.46639633178711\n",
      "Epoch [402/600], Training Loss: 16.0374\n",
      "Validation Loss: 26.3917, valid error: 26.809097290039062\n",
      "Epoch [403/600], Training Loss: 16.4323\n",
      "Validation Loss: 23.3384, valid error: 23.756378173828125\n",
      "Epoch [404/600], Training Loss: 16.0876\n",
      "Validation Loss: 23.2909, valid error: 23.70864486694336\n",
      "Epoch [405/600], Training Loss: 15.4369\n",
      "Validation Loss: 22.8575, valid error: 23.271326065063477\n",
      "Epoch [406/600], Training Loss: 15.1470\n",
      "Validation Loss: 21.5915, valid error: 22.00771713256836\n",
      "Epoch [407/600], Training Loss: 14.9217\n",
      "Validation Loss: 22.6554, valid error: 23.071090698242188\n",
      "Epoch [408/600], Training Loss: 14.8078\n",
      "Validation Loss: 21.5283, valid error: 21.943044662475586\n",
      "Epoch [409/600], Training Loss: 14.6398\n",
      "Validation Loss: 22.1598, valid error: 22.574932098388672\n",
      "Epoch [410/600], Training Loss: 14.5196\n",
      "Validation Loss: 21.6382, valid error: 22.054115295410156\n",
      "Epoch [411/600], Training Loss: 14.6437\n",
      "Validation Loss: 22.3820, valid error: 22.79922103881836\n",
      "Epoch [412/600], Training Loss: 14.4543\n",
      "Validation Loss: 21.9414, valid error: 22.356189727783203\n",
      "Epoch [413/600], Training Loss: 14.4516\n",
      "Validation Loss: 22.7151, valid error: 23.134037017822266\n",
      "Epoch [414/600], Training Loss: 14.2999\n",
      "Validation Loss: 21.6288, valid error: 22.042898178100586\n",
      "Epoch [415/600], Training Loss: 14.6412\n",
      "Validation Loss: 23.1979, valid error: 23.615873336791992\n",
      "Epoch [416/600], Training Loss: 14.7190\n",
      "Validation Loss: 22.2736, valid error: 22.68900489807129\n",
      "Epoch [417/600], Training Loss: 14.7973\n",
      "Validation Loss: 22.7218, valid error: 23.139122009277344\n",
      "Epoch [418/600], Training Loss: 14.9259\n",
      "Validation Loss: 22.0234, valid error: 22.440086364746094\n",
      "Epoch [419/600], Training Loss: 14.9479\n",
      "Validation Loss: 21.6446, valid error: 22.0591983795166\n",
      "Epoch [420/600], Training Loss: 14.5015\n",
      "Validation Loss: 22.6236, valid error: 23.03990936279297\n",
      "Epoch [421/600], Training Loss: 14.6126\n",
      "Validation Loss: 21.4769, valid error: 21.892959594726562\n",
      "Epoch [422/600], Training Loss: 14.7586\n",
      "Validation Loss: 21.1168, valid error: 21.532442092895508\n",
      "Epoch [423/600], Training Loss: 14.3659\n",
      "Validation Loss: 21.1752, valid error: 21.59075355529785\n",
      "Epoch [424/600], Training Loss: 14.7649\n",
      "Validation Loss: 22.2401, valid error: 22.65861701965332\n",
      "Epoch [425/600], Training Loss: 14.3429\n",
      "Validation Loss: 21.9393, valid error: 22.356103897094727\n",
      "Epoch [426/600], Training Loss: 13.7844\n",
      "Validation Loss: 22.3599, valid error: 22.77627182006836\n",
      "Epoch [427/600], Training Loss: 14.0962\n",
      "Validation Loss: 21.9872, valid error: 22.402904510498047\n",
      "Epoch [428/600], Training Loss: 13.8390\n",
      "Validation Loss: 22.0615, valid error: 22.487194061279297\n",
      "Epoch [429/600], Training Loss: 14.7473\n",
      "Validation Loss: 23.3976, valid error: 23.816373825073242\n",
      "Epoch [430/600], Training Loss: 14.4373\n",
      "Validation Loss: 24.0889, valid error: 24.50745391845703\n",
      "Epoch [431/600], Training Loss: 14.6841\n",
      "Validation Loss: 25.4633, valid error: 25.881980895996094\n",
      "Epoch [432/600], Training Loss: 14.3781\n",
      "Validation Loss: 23.1626, valid error: 23.579708099365234\n",
      "Epoch [433/600], Training Loss: 15.0136\n",
      "Validation Loss: 23.6476, valid error: 24.062179565429688\n",
      "Epoch [434/600], Training Loss: 14.7209\n",
      "Validation Loss: 23.0539, valid error: 23.469539642333984\n",
      "Epoch [435/600], Training Loss: 14.5665\n",
      "Validation Loss: 23.8010, valid error: 24.218666076660156\n",
      "Epoch [436/600], Training Loss: 14.3058\n",
      "Validation Loss: 24.4486, valid error: 24.86740493774414\n",
      "Epoch [437/600], Training Loss: 14.4114\n",
      "Validation Loss: 22.7265, valid error: 23.142559051513672\n",
      "Epoch [438/600], Training Loss: 13.9661\n",
      "Validation Loss: 22.5298, valid error: 22.945968627929688\n",
      "Epoch [439/600], Training Loss: 13.5221\n",
      "Validation Loss: 22.3061, valid error: 22.72039794921875\n",
      "Epoch [440/600], Training Loss: 13.2870\n",
      "Validation Loss: 21.4320, valid error: 21.848447799682617\n",
      "Epoch [441/600], Training Loss: 13.0470\n",
      "Validation Loss: 21.4068, valid error: 21.820926666259766\n",
      "Epoch [442/600], Training Loss: 13.1089\n",
      "Validation Loss: 20.8749, valid error: 21.290124893188477\n",
      "Epoch [443/600], Training Loss: 13.1633\n",
      "Validation Loss: 21.0110, valid error: 21.42475700378418\n",
      "Epoch [444/600], Training Loss: 12.8381\n",
      "Validation Loss: 21.5126, valid error: 21.92769432067871\n",
      "Epoch [445/600], Training Loss: 12.8057\n",
      "Validation Loss: 21.0334, valid error: 21.447275161743164\n",
      "Epoch [446/600], Training Loss: 12.6645\n",
      "Validation Loss: 21.0534, valid error: 21.467981338500977\n",
      "Epoch [447/600], Training Loss: 12.9294\n",
      "Validation Loss: 20.4765, valid error: 20.89316177368164\n",
      "Epoch [448/600], Training Loss: 12.7874\n",
      "Validation Loss: 21.4822, valid error: 21.896236419677734\n",
      "Epoch [449/600], Training Loss: 12.8236\n",
      "Validation Loss: 20.7587, valid error: 21.17263412475586\n",
      "Epoch [450/600], Training Loss: 12.6263\n",
      "Validation Loss: 20.7221, valid error: 21.13506507873535\n",
      "Epoch [451/600], Training Loss: 12.4067\n",
      "Validation Loss: 21.3020, valid error: 21.718896865844727\n",
      "Epoch [452/600], Training Loss: 12.6221\n",
      "Validation Loss: 21.2734, valid error: 21.687488555908203\n",
      "Epoch [453/600], Training Loss: 12.7881\n",
      "Validation Loss: 22.2173, valid error: 22.636024475097656\n",
      "Epoch [454/600], Training Loss: 12.8641\n",
      "Validation Loss: 21.0858, valid error: 21.50370216369629\n",
      "Epoch [455/600], Training Loss: 13.5032\n",
      "Validation Loss: 21.6061, valid error: 22.022491455078125\n",
      "Epoch [456/600], Training Loss: 13.7105\n",
      "Validation Loss: 21.3473, valid error: 21.76138687133789\n",
      "Epoch [457/600], Training Loss: 13.1094\n",
      "Validation Loss: 21.5186, valid error: 21.936424255371094\n",
      "Epoch [458/600], Training Loss: 13.4492\n",
      "Validation Loss: 21.2294, valid error: 21.647260665893555\n",
      "Epoch [459/600], Training Loss: 13.2101\n",
      "Validation Loss: 21.4152, valid error: 21.833240509033203\n",
      "Epoch [460/600], Training Loss: 13.4081\n",
      "Validation Loss: 21.3492, valid error: 21.764986038208008\n",
      "Epoch [461/600], Training Loss: 13.4557\n",
      "Validation Loss: 21.2584, valid error: 21.676258087158203\n",
      "Epoch [462/600], Training Loss: 13.3022\n",
      "Validation Loss: 21.2209, valid error: 21.643131256103516\n",
      "Epoch [463/600], Training Loss: 13.2543\n",
      "Validation Loss: 21.5595, valid error: 21.9778995513916\n",
      "Epoch [464/600], Training Loss: 12.6853\n",
      "Validation Loss: 21.3320, valid error: 21.75208854675293\n",
      "Epoch [465/600], Training Loss: 12.6751\n",
      "Validation Loss: 21.6167, valid error: 22.03371238708496\n",
      "Epoch [466/600], Training Loss: 12.6529\n",
      "Validation Loss: 21.7894, valid error: 22.20714569091797\n",
      "Epoch [467/600], Training Loss: 12.8583\n",
      "Validation Loss: 22.2509, valid error: 22.674118041992188\n",
      "Epoch [468/600], Training Loss: 13.0078\n",
      "Validation Loss: 24.0928, valid error: 24.51502227783203\n",
      "Epoch [469/600], Training Loss: 12.6880\n",
      "Validation Loss: 23.8672, valid error: 24.2851505279541\n",
      "Epoch [470/600], Training Loss: 12.5746\n",
      "Validation Loss: 23.1341, valid error: 23.546859741210938\n",
      "Epoch [471/600], Training Loss: 12.7838\n",
      "Validation Loss: 22.4617, valid error: 22.882808685302734\n",
      "Epoch [472/600], Training Loss: 12.8513\n",
      "Validation Loss: 23.7991, valid error: 24.216217041015625\n",
      "Epoch [473/600], Training Loss: 12.8153\n",
      "Validation Loss: 24.2034, valid error: 24.620254516601562\n",
      "Epoch [474/600], Training Loss: 12.8776\n",
      "Validation Loss: 25.0288, valid error: 25.443492889404297\n",
      "Epoch [475/600], Training Loss: 13.6914\n",
      "Validation Loss: 21.9320, valid error: 22.347190856933594\n",
      "Epoch [476/600], Training Loss: 13.4039\n",
      "Validation Loss: 21.7103, valid error: 22.1263427734375\n",
      "Epoch [477/600], Training Loss: 13.1289\n",
      "Validation Loss: 22.3132, valid error: 22.728389739990234\n",
      "Epoch [478/600], Training Loss: 12.5145\n",
      "Validation Loss: 20.9275, valid error: 21.342741012573242\n",
      "Epoch [479/600], Training Loss: 12.5335\n",
      "Validation Loss: 20.3335, valid error: 20.74740982055664\n",
      "Epoch [480/600], Training Loss: 12.3266\n",
      "Validation Loss: 20.6137, valid error: 21.02819061279297\n",
      "Epoch [481/600], Training Loss: 12.2476\n",
      "Validation Loss: 20.3332, valid error: 20.750795364379883\n",
      "Epoch [482/600], Training Loss: 12.1339\n",
      "Validation Loss: 20.9486, valid error: 21.364898681640625\n",
      "Epoch [483/600], Training Loss: 11.7748\n",
      "Validation Loss: 20.7216, valid error: 21.135854721069336\n",
      "Epoch [484/600], Training Loss: 12.1719\n",
      "Validation Loss: 21.3801, valid error: 21.795541763305664\n",
      "Epoch [485/600], Training Loss: 12.2721\n",
      "Validation Loss: 22.7668, valid error: 23.18383026123047\n",
      "Epoch [486/600], Training Loss: 13.9300\n",
      "Validation Loss: 21.5732, valid error: 21.993432998657227\n",
      "Epoch [487/600], Training Loss: 13.8084\n",
      "Validation Loss: 21.5202, valid error: 21.939212799072266\n",
      "Epoch [488/600], Training Loss: 13.0478\n",
      "Validation Loss: 21.6468, valid error: 22.066146850585938\n",
      "Epoch [489/600], Training Loss: 12.3535\n",
      "Validation Loss: 21.4089, valid error: 21.824806213378906\n",
      "Epoch [490/600], Training Loss: 12.1830\n",
      "Validation Loss: 21.5621, valid error: 21.978137969970703\n",
      "Epoch [491/600], Training Loss: 11.8800\n",
      "Validation Loss: 21.6842, valid error: 22.10010528564453\n",
      "Epoch [492/600], Training Loss: 11.9829\n",
      "Validation Loss: 21.0349, valid error: 21.450050354003906\n",
      "Epoch [493/600], Training Loss: 12.1830\n",
      "Validation Loss: 21.1265, valid error: 21.539743423461914\n",
      "Epoch [494/600], Training Loss: 12.0434\n",
      "Validation Loss: 21.4752, valid error: 21.89130210876465\n",
      "Epoch [495/600], Training Loss: 12.0009\n",
      "Validation Loss: 21.5495, valid error: 21.967910766601562\n",
      "Epoch [496/600], Training Loss: 11.8294\n",
      "Validation Loss: 21.1030, valid error: 21.52188491821289\n",
      "Epoch [497/600], Training Loss: 12.3587\n",
      "Validation Loss: 22.3112, valid error: 22.72490692138672\n",
      "Epoch [498/600], Training Loss: 12.4086\n",
      "Validation Loss: 22.4144, valid error: 22.830778121948242\n",
      "Epoch [499/600], Training Loss: 12.1636\n",
      "Validation Loss: 24.0782, valid error: 24.49687957763672\n",
      "Epoch [500/600], Training Loss: 12.0241\n",
      "Validation Loss: 24.1642, valid error: 24.577545166015625\n",
      "Epoch [501/600], Training Loss: 12.7178\n",
      "Validation Loss: 23.1957, valid error: 23.609180450439453\n",
      "Epoch [502/600], Training Loss: 12.7203\n",
      "Validation Loss: 22.7051, valid error: 23.12070083618164\n",
      "Epoch [503/600], Training Loss: 12.0579\n",
      "Validation Loss: 22.8615, valid error: 23.279417037963867\n",
      "Epoch [504/600], Training Loss: 11.9752\n",
      "Validation Loss: 22.0832, valid error: 22.49539566040039\n",
      "Epoch [505/600], Training Loss: 11.8896\n",
      "Validation Loss: 20.4661, valid error: 20.878990173339844\n",
      "Epoch [506/600], Training Loss: 11.7562\n",
      "Validation Loss: 21.0187, valid error: 21.43018341064453\n",
      "Epoch [507/600], Training Loss: 11.6556\n",
      "Validation Loss: 20.8430, valid error: 21.253511428833008\n",
      "Epoch [508/600], Training Loss: 11.5578\n",
      "Validation Loss: 20.5222, valid error: 20.934429168701172\n",
      "Epoch [509/600], Training Loss: 11.5763\n",
      "Validation Loss: 20.6363, valid error: 21.047849655151367\n",
      "Epoch [510/600], Training Loss: 11.4523\n",
      "Validation Loss: 20.6353, valid error: 21.050098419189453\n",
      "Epoch [511/600], Training Loss: 11.4438\n",
      "Validation Loss: 21.0404, valid error: 21.453170776367188\n",
      "Epoch [512/600], Training Loss: 11.2007\n",
      "Validation Loss: 21.4988, valid error: 21.910175323486328\n",
      "Epoch [513/600], Training Loss: 11.4015\n",
      "Validation Loss: 21.9435, valid error: 22.35179328918457\n",
      "Epoch [514/600], Training Loss: 11.5063\n",
      "Validation Loss: 21.5705, valid error: 21.98133087158203\n",
      "Epoch [515/600], Training Loss: 11.8117\n",
      "Validation Loss: 21.9604, valid error: 22.37529182434082\n",
      "Epoch [516/600], Training Loss: 12.0431\n",
      "Validation Loss: 21.6020, valid error: 22.011077880859375\n",
      "Epoch [517/600], Training Loss: 11.8882\n",
      "Validation Loss: 21.5725, valid error: 21.98027992248535\n",
      "Epoch [518/600], Training Loss: 12.0510\n",
      "Validation Loss: 21.1291, valid error: 21.537336349487305\n",
      "Epoch [519/600], Training Loss: 11.9951\n",
      "Validation Loss: 21.3401, valid error: 21.75067138671875\n",
      "Epoch [520/600], Training Loss: 12.3092\n",
      "Validation Loss: 22.9453, valid error: 23.35417938232422\n",
      "Epoch [521/600], Training Loss: 12.3312\n",
      "Validation Loss: 21.9742, valid error: 22.38632583618164\n",
      "Epoch [522/600], Training Loss: 12.8767\n",
      "Validation Loss: 23.4015, valid error: 23.810997009277344\n",
      "Epoch [523/600], Training Loss: 12.3025\n",
      "Validation Loss: 25.2586, valid error: 25.667034149169922\n",
      "Epoch [524/600], Training Loss: 12.6011\n",
      "Validation Loss: 25.4134, valid error: 25.81835174560547\n",
      "Epoch [525/600], Training Loss: 12.7930\n",
      "Validation Loss: 24.1098, valid error: 24.516719818115234\n",
      "Epoch [526/600], Training Loss: 12.8774\n",
      "Validation Loss: 22.9699, valid error: 23.378278732299805\n",
      "Epoch [527/600], Training Loss: 12.3618\n",
      "Validation Loss: 21.6715, valid error: 22.08016014099121\n",
      "Epoch [528/600], Training Loss: 12.3997\n",
      "Validation Loss: 20.6801, valid error: 21.091039657592773\n",
      "Epoch [529/600], Training Loss: 11.8943\n",
      "Validation Loss: 21.1748, valid error: 21.5822811126709\n",
      "Epoch [530/600], Training Loss: 11.7425\n",
      "Validation Loss: 21.4190, valid error: 21.819501876831055\n",
      "Epoch [531/600], Training Loss: 11.9595\n",
      "Validation Loss: 22.5833, valid error: 22.983461380004883\n",
      "Epoch [532/600], Training Loss: 11.7902\n",
      "Validation Loss: 22.4547, valid error: 22.85466766357422\n",
      "Epoch [533/600], Training Loss: 11.8004\n",
      "Validation Loss: 21.7840, valid error: 22.18549156188965\n",
      "Epoch [534/600], Training Loss: 11.6492\n",
      "Validation Loss: 21.0268, valid error: 21.428768157958984\n",
      "Epoch [535/600], Training Loss: 11.6602\n",
      "Validation Loss: 21.2594, valid error: 21.66343879699707\n",
      "Epoch [536/600], Training Loss: 11.5915\n",
      "Validation Loss: 22.8737, valid error: 23.275531768798828\n",
      "Epoch [537/600], Training Loss: 11.6385\n",
      "Validation Loss: 22.7003, valid error: 23.107742309570312\n",
      "Epoch [538/600], Training Loss: 11.7871\n",
      "Validation Loss: 24.4406, valid error: 24.837017059326172\n",
      "Epoch [539/600], Training Loss: 12.0444\n",
      "Validation Loss: 24.2899, valid error: 24.687166213989258\n",
      "Epoch [540/600], Training Loss: 12.6068\n",
      "Validation Loss: 23.7213, valid error: 24.113079071044922\n",
      "Epoch [541/600], Training Loss: 12.3863\n",
      "Validation Loss: 22.5842, valid error: 22.980026245117188\n",
      "Epoch [542/600], Training Loss: 12.2130\n",
      "Validation Loss: 21.6599, valid error: 22.062816619873047\n",
      "Epoch [543/600], Training Loss: 12.0398\n",
      "Validation Loss: 20.5292, valid error: 20.93497657775879\n",
      "Epoch [544/600], Training Loss: 11.5805\n",
      "Validation Loss: 22.1862, valid error: 22.57910919189453\n",
      "Epoch [545/600], Training Loss: 11.8865\n",
      "Validation Loss: 21.6482, valid error: 22.037384033203125\n",
      "Epoch [546/600], Training Loss: 11.2818\n",
      "Validation Loss: 22.6876, valid error: 23.078887939453125\n",
      "Epoch [547/600], Training Loss: 11.6026\n",
      "Validation Loss: 20.4726, valid error: 20.864238739013672\n",
      "Epoch [548/600], Training Loss: 11.4958\n",
      "Validation Loss: 20.9620, valid error: 21.356216430664062\n",
      "Epoch [549/600], Training Loss: 11.0836\n",
      "Validation Loss: 21.1272, valid error: 21.519880294799805\n",
      "Epoch [550/600], Training Loss: 11.0832\n",
      "Validation Loss: 22.4784, valid error: 22.871999740600586\n",
      "Epoch [551/600], Training Loss: 11.3519\n",
      "Validation Loss: 23.2121, valid error: 23.603490829467773\n",
      "Epoch [552/600], Training Loss: 11.3718\n",
      "Validation Loss: 23.1830, valid error: 23.567466735839844\n",
      "Epoch [553/600], Training Loss: 11.7060\n",
      "Validation Loss: 21.2220, valid error: 21.607519149780273\n",
      "Epoch [554/600], Training Loss: 11.4204\n",
      "Validation Loss: 21.1641, valid error: 21.546781539916992\n",
      "Epoch [555/600], Training Loss: 10.7143\n",
      "Validation Loss: 20.5965, valid error: 20.986469268798828\n",
      "Epoch [556/600], Training Loss: 10.5510\n",
      "Validation Loss: 20.9396, valid error: 21.328948974609375\n",
      "Epoch [557/600], Training Loss: 10.7138\n",
      "Validation Loss: 20.7834, valid error: 21.16397476196289\n",
      "Epoch [558/600], Training Loss: 10.6727\n",
      "Validation Loss: 22.4419, valid error: 22.824970245361328\n",
      "Epoch [559/600], Training Loss: 10.9273\n",
      "Validation Loss: 21.9694, valid error: 22.34914779663086\n",
      "Epoch [560/600], Training Loss: 10.7701\n",
      "Validation Loss: 21.8984, valid error: 22.27791976928711\n",
      "Epoch [561/600], Training Loss: 10.9179\n",
      "Validation Loss: 21.4867, valid error: 21.866302490234375\n",
      "Epoch [562/600], Training Loss: 11.0304\n",
      "Validation Loss: 21.7333, valid error: 22.11383819580078\n",
      "Epoch [563/600], Training Loss: 11.1799\n",
      "Validation Loss: 22.8994, valid error: 23.282028198242188\n",
      "Epoch [564/600], Training Loss: 11.3043\n",
      "Validation Loss: 24.3398, valid error: 24.71782684326172\n",
      "Epoch [565/600], Training Loss: 11.7369\n",
      "Validation Loss: 23.7438, valid error: 24.120332717895508\n",
      "Epoch [566/600], Training Loss: 11.8985\n",
      "Validation Loss: 22.3822, valid error: 22.763050079345703\n",
      "Epoch [567/600], Training Loss: 11.4473\n",
      "Validation Loss: 21.1176, valid error: 21.50128746032715\n",
      "Epoch [568/600], Training Loss: 10.9887\n",
      "Validation Loss: 21.3425, valid error: 21.717113494873047\n",
      "Epoch [569/600], Training Loss: 10.6666\n",
      "Validation Loss: 21.3630, valid error: 21.752044677734375\n",
      "Epoch [570/600], Training Loss: 10.3494\n",
      "Validation Loss: 21.1696, valid error: 21.54427719116211\n",
      "Epoch [571/600], Training Loss: 10.6771\n",
      "Validation Loss: 21.7762, valid error: 22.146121978759766\n",
      "Epoch [572/600], Training Loss: 10.5494\n",
      "Validation Loss: 21.8477, valid error: 22.21812629699707\n",
      "Epoch [573/600], Training Loss: 11.1663\n",
      "Validation Loss: 20.9147, valid error: 21.28780746459961\n",
      "Epoch [574/600], Training Loss: 12.8226\n",
      "Validation Loss: 22.3428, valid error: 22.722352981567383\n",
      "Epoch [575/600], Training Loss: 11.8798\n",
      "Validation Loss: 21.4459, valid error: 21.816761016845703\n",
      "Epoch [576/600], Training Loss: 10.9222\n",
      "Validation Loss: 22.8009, valid error: 23.17669677734375\n",
      "Epoch [577/600], Training Loss: 10.6237\n",
      "Validation Loss: 22.5686, valid error: 22.934850692749023\n",
      "Epoch [578/600], Training Loss: 10.6045\n",
      "Validation Loss: 22.3915, valid error: 22.76190948486328\n",
      "Epoch [579/600], Training Loss: 10.5497\n",
      "Validation Loss: 22.2459, valid error: 22.615585327148438\n",
      "Epoch [580/600], Training Loss: 10.6076\n",
      "Validation Loss: 21.5022, valid error: 21.873714447021484\n",
      "Epoch [581/600], Training Loss: 10.4161\n",
      "Validation Loss: 20.8624, valid error: 21.230621337890625\n",
      "Epoch [582/600], Training Loss: 10.3826\n",
      "Validation Loss: 20.3267, valid error: 20.696603775024414\n",
      "Epoch [583/600], Training Loss: 10.3600\n",
      "Validation Loss: 20.5055, valid error: 20.868295669555664\n",
      "Epoch [584/600], Training Loss: 10.5273\n",
      "Validation Loss: 21.1079, valid error: 21.469783782958984\n",
      "Epoch [585/600], Training Loss: 10.7306\n",
      "Validation Loss: 22.3117, valid error: 22.67626953125\n",
      "Epoch [586/600], Training Loss: 10.8020\n",
      "Validation Loss: 21.3183, valid error: 21.67766761779785\n",
      "Epoch [587/600], Training Loss: 10.6915\n",
      "Validation Loss: 20.6131, valid error: 20.97868537902832\n",
      "Epoch [588/600], Training Loss: 10.4046\n",
      "Validation Loss: 21.5790, valid error: 21.942033767700195\n",
      "Epoch [589/600], Training Loss: 10.5383\n",
      "Validation Loss: 20.7295, valid error: 21.095703125\n",
      "Epoch [590/600], Training Loss: 10.3872\n",
      "Validation Loss: 22.9319, valid error: 23.291393280029297\n",
      "Epoch [591/600], Training Loss: 10.6982\n",
      "Validation Loss: 22.2262, valid error: 22.581336975097656\n",
      "Epoch [592/600], Training Loss: 10.7462\n",
      "Validation Loss: 21.9910, valid error: 22.34969711303711\n",
      "Epoch [593/600], Training Loss: 10.5952\n",
      "Validation Loss: 20.9478, valid error: 21.306272506713867\n",
      "Epoch [594/600], Training Loss: 10.3689\n",
      "Validation Loss: 21.2731, valid error: 21.628376007080078\n",
      "Epoch [595/600], Training Loss: 10.4678\n",
      "Validation Loss: 21.0820, valid error: 21.43869400024414\n",
      "Epoch [596/600], Training Loss: 10.4191\n",
      "Validation Loss: 21.0404, valid error: 21.393592834472656\n",
      "Epoch [597/600], Training Loss: 10.3182\n",
      "Validation Loss: 21.1639, valid error: 21.515399932861328\n",
      "Epoch [598/600], Training Loss: 10.0592\n",
      "Validation Loss: 20.8913, valid error: 21.242107391357422\n",
      "Epoch [599/600], Training Loss: 10.3465\n",
      "Validation Loss: 21.6974, valid error: 22.049041748046875\n",
      "Epoch [600/600], Training Loss: 10.2218\n",
      "Validation Loss: 20.7174, valid error: 21.069089889526367\n"
     ]
    }
   ],
   "source": [
    "model = LSTMTagger(256, 1, input_dim=5)\n",
    "train_length, valid_length = len(batch_train_data), len(batch_valid_data)\n",
    "train_model(model, train_loader, valid_loader, train_length, valid_length, 600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train MAE\n",
      "12.786532920542376 124967\n",
      "valid MAE\n",
      "26.743069725561018 6723\n"
     ]
    }
   ],
   "source": [
    "def show(model, loader, device):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    data_num = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, lengths in loader:\n",
    "            inputs, lengths = inputs.to(device, dtype=torch.float32), lengths.to('cpu', dtype=torch.int64)\n",
    "            \n",
    "            hidden = model.init_hidden(batch_size=inputs.size(0))\n",
    "            hidden = tuple([h.to(device, dtype=torch.float32) for h in hidden])\n",
    "            outputs, _ = model(inputs, hidden, lengths)\n",
    "            outputs = outputs.to('cpu', dtype=torch.float32).view(labels.shape[0], -1)\n",
    "\n",
    "            \n",
    "            for i in range(labels.shape[0]):\n",
    "                length = lengths[i]\n",
    "                error += abs(outputs[i, :length] - labels[i, :length]).sum()\n",
    "                data_num += length\n",
    "\n",
    "    print(float(error) / int(data_num), int(data_num))\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)\n",
    "print(\"train MAE\")\n",
    "show(model, train_loader, device)\n",
    "print(\"valid MAE\")\n",
    "show(model, valid_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
